{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas  as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:\\\\Users\\\\nitin2351\\\\train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Tourists  Temp  Target  Month  Year\n",
      "0   4205366  29.7   39483      1  2011\n",
      "1   3850922  36.0   39721      2  2011\n",
      "2   4783693  42.3   39466      3  2011\n",
      "3   5516050  54.3   39017      4  2011\n",
      "4   5201075  64.5   38802      5  2011\n"
     ]
    }
   ],
   "source": [
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8     6\n",
      "7     6\n",
      "6     6\n",
      "5     6\n",
      "4     6\n",
      "3     6\n",
      "2     6\n",
      "1     6\n",
      "12    5\n",
      "11    5\n",
      "10    5\n",
      "9     5\n",
      "Name: Month, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['Month'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X=df.drop(\"Target\",1)\n",
    "y=df.Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "q1 = np.percentile(X.Tourists, 25)\n",
    "q3 = np.percentile(X.Tourists, 75)\n",
    "iqr = q3-q1 \n",
    "floor = q1 - 1.5*iqr\n",
    "ceiling = q3 + 1.5*iqr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.75926957, -2.12535342, -1.16195047, -0.40554305, -0.73086175,\n",
       "       -1.08068457,  0.72970378,  0.78744469, -0.5754989 , -0.65762618,\n",
       "       -1.07241152, -0.80870895, -1.2869313 , -1.83867119, -0.6377688 ,\n",
       "       -0.22733791, -0.62986242, -0.79241073,  1.14322803,  1.40605062,\n",
       "       -0.15056074, -0.37989454, -0.70030002, -0.29068301, -1.15343987,\n",
       "       -1.60143514, -0.07114156, -0.3162933 , -0.239638  , -0.41357131,\n",
       "        1.13569449,  1.96797122,  0.11086546, -0.03045594, -0.54795513,\n",
       "       -0.01383238, -0.56595959, -1.30627123, -0.03936934,  0.58652431,\n",
       "        0.44835824,  0.06599374,  1.53118639,  2.53690376,  0.33187457,\n",
       "        0.41812392, -0.10822257,  0.3424178 , -0.44081763, -1.0610854 ,\n",
       "        0.25432896,  0.61337917,  0.97313172,  0.29374626,  1.98725743,\n",
       "        1.98725743,  0.6226799 ,  0.70741923,  0.14180211,  0.4367233 ,\n",
       "       -0.41038087, -1.07767074,  0.26426178,  0.07177247,  0.57851154,\n",
       "        0.29374729,  1.82428875,  2.11722069])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import scale\n",
    "\n",
    "scale(list(map(float,X.Tourists)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outlier_values = list(X[outlier_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tourists</th>\n",
       "      <th>Temp</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4205366</td>\n",
       "      <td>29.7</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3850922</td>\n",
       "      <td>36.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4783693</td>\n",
       "      <td>42.3</td>\n",
       "      <td>3</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5516050</td>\n",
       "      <td>54.3</td>\n",
       "      <td>4</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5201075</td>\n",
       "      <td>64.5</td>\n",
       "      <td>5</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Tourists  Temp  Month  Year\n",
       "0   4205366  29.7      1  2011\n",
       "1   3850922  36.0      2  2011\n",
       "2   4783693  42.3      3  2011\n",
       "3   5516050  54.3      4  2011\n",
       "4   5201075  64.5      5  2011"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    39483\n",
       "1    39721\n",
       "2    39466\n",
       "3    39017\n",
       "4    38802\n",
       "5    38470\n",
       "Name: Target, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   2011  2012  2013  2014  2015  2016\n",
      "0   1.0   0.0   0.0   0.0   0.0   0.0\n",
      "1   1.0   0.0   0.0   0.0   0.0   0.0\n",
      "2   1.0   0.0   0.0   0.0   0.0   0.0\n",
      "3   1.0   0.0   0.0   0.0   0.0   0.0\n",
      "4   1.0   0.0   0.0   0.0   0.0   0.0\n"
     ]
    }
   ],
   "source": [
    "print(pd.get_dummies(X['Year']).head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'Tourists', u'Temp', u'Month', u'Year'], dtype='object')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "todummy_list = ['Year', 'Month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def dummy_df(df, todummy_list):\n",
    "    for x in todummy_list:\n",
    "        dummies = pd.get_dummies(df[x], prefix=x, dummy_na=False)\n",
    "        df = df.drop(x, 1)\n",
    "        df = pd.concat([df, dummies], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df=dummy_df(df,todummy_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tourists</th>\n",
       "      <th>Temp</th>\n",
       "      <th>Target</th>\n",
       "      <th>Year_2011</th>\n",
       "      <th>Year_2012</th>\n",
       "      <th>Year_2013</th>\n",
       "      <th>Year_2014</th>\n",
       "      <th>Year_2015</th>\n",
       "      <th>Year_2016</th>\n",
       "      <th>Month_1</th>\n",
       "      <th>...</th>\n",
       "      <th>Month_3</th>\n",
       "      <th>Month_4</th>\n",
       "      <th>Month_5</th>\n",
       "      <th>Month_6</th>\n",
       "      <th>Month_7</th>\n",
       "      <th>Month_8</th>\n",
       "      <th>Month_9</th>\n",
       "      <th>Month_10</th>\n",
       "      <th>Month_11</th>\n",
       "      <th>Month_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4205366</td>\n",
       "      <td>29.7</td>\n",
       "      <td>39483</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3850922</td>\n",
       "      <td>36.0</td>\n",
       "      <td>39721</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4783693</td>\n",
       "      <td>42.3</td>\n",
       "      <td>39466</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5516050</td>\n",
       "      <td>54.3</td>\n",
       "      <td>39017</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5201075</td>\n",
       "      <td>64.5</td>\n",
       "      <td>38802</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Tourists  Temp  Target  Year_2011  Year_2012  Year_2013  Year_2014  \\\n",
       "0   4205366  29.7   39483        1.0        0.0        0.0        0.0   \n",
       "1   3850922  36.0   39721        1.0        0.0        0.0        0.0   \n",
       "2   4783693  42.3   39466        1.0        0.0        0.0        0.0   \n",
       "3   5516050  54.3   39017        1.0        0.0        0.0        0.0   \n",
       "4   5201075  64.5   38802        1.0        0.0        0.0        0.0   \n",
       "\n",
       "   Year_2015  Year_2016  Month_1    ...     Month_3  Month_4  Month_5  \\\n",
       "0        0.0        0.0      1.0    ...         0.0      0.0      0.0   \n",
       "1        0.0        0.0      0.0    ...         0.0      0.0      0.0   \n",
       "2        0.0        0.0      0.0    ...         1.0      0.0      0.0   \n",
       "3        0.0        0.0      0.0    ...         0.0      1.0      0.0   \n",
       "4        0.0        0.0      0.0    ...         0.0      0.0      1.0   \n",
       "\n",
       "   Month_6  Month_7  Month_8  Month_9  Month_10  Month_11  Month_12  \n",
       "0      0.0      0.0      0.0      0.0       0.0       0.0       0.0  \n",
       "1      0.0      0.0      0.0      0.0       0.0       0.0       0.0  \n",
       "2      0.0      0.0      0.0      0.0       0.0       0.0       0.0  \n",
       "3      0.0      0.0      0.0      0.0       0.0       0.0       0.0  \n",
       "4      0.0      0.0      0.0      0.0       0.0       0.0       0.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-57a90e81f01d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Target\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "X=df.drop(\"Target\",1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y=df.Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s=X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'Tourists', u'Temp', u'Year_2011', u'Year_2012', u'Year_2013',\n",
       "       u'Year_2014', u'Year_2015', u'Year_2016', u'Month_1', u'Month_2',\n",
       "       u'Month_3', u'Month_4', u'Month_5', u'Month_6', u'Month_7', u'Month_8',\n",
       "       u'Month_9', u'Month_10', u'Month_11', u'Month_12'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#X.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X = pd.DataFrame(min_max_scaler.fit_transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0         1    2    3    4    5    6    7    8    9    10   11   12  \\\n",
      "0  0.078521  0.103020  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0   \n",
      "1  0.000000  0.214920  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0   \n",
      "2  0.206639  0.326821  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0   \n",
      "3  0.368879  0.539964  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0   \n",
      "4  0.299102  0.721137  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
      "\n",
      "    13   14   15   16   17   18   19  \n",
      "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n"
     ]
    }
   ],
   "source": [
    "print(X.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X.columns=s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-7045313b4e34>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "X.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Node:\n",
    "    \"\"\"\n",
    "    Base class for nodes in the network.\n",
    "\n",
    "    Arguments:\n",
    "\n",
    "        `inbound_nodes`: A list of nodes with edges into this node.\n",
    "    \"\"\"\n",
    "    def __init__(self, inbound_nodes=[]):\n",
    "        \"\"\"\n",
    "        Node's constructor (runs when the object is instantiated). Sets\n",
    "        properties that all nodes need.\n",
    "        \"\"\"\n",
    "        # A list of nodes with edges into this node.\n",
    "        self.inbound_nodes = inbound_nodes\n",
    "        # The eventual value of this node. Set by running\n",
    "        # the forward() method.\n",
    "        self.value = None\n",
    "        # A list of nodes that this node outputs to.\n",
    "        self.outbound_nodes = []\n",
    "        # New property! Keys are the inputs to this node and\n",
    "        # their values are the partials of this node with\n",
    "        # respect to that input.\n",
    "        self.gradients = {}\n",
    "        # Sets this node as an outbound node for all of\n",
    "        # this node's inputs.\n",
    "        for node in inbound_nodes:\n",
    "            node.outbound_nodes.append(self)\n",
    "\n",
    "    def forward(self):\n",
    "        \"\"\"\n",
    "        Every node that uses this class as a base class will\n",
    "        need to define its own `forward` method.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def backward(self):\n",
    "        \"\"\"\n",
    "        Every node that uses this class as a base class will\n",
    "        need to define its own `backward` method.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "class Input(Node):\n",
    "    \"\"\"\n",
    "    A generic input into the network.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        # The base class constructor has to run to set all\n",
    "        # the properties here.\n",
    "        #\n",
    "        # The most important property on an Input is value.\n",
    "        # self.value is set during `topological_sort` later.\n",
    "        Node.__init__(self)\n",
    "\n",
    "    def forward(self):\n",
    "        # Do nothing because nothing is calculated.\n",
    "        pass\n",
    "\n",
    "    def backward(self):\n",
    "        # An Input node has no inputs so the gradient (derivative)\n",
    "        # is zero.\n",
    "        # The key, `self`, is reference to this object.\n",
    "        self.gradients = {self: 0}\n",
    "        # Weights and bias may be inputs, so you need to sum\n",
    "        # the gradient from output gradients.\n",
    "        for n in self.outbound_nodes:\n",
    "            self.gradients[self] += n.gradients[self]\n",
    "\n",
    "class Linear(Node):\n",
    "    \"\"\"\n",
    "    Represents a node that performs a linear transform.\n",
    "    \"\"\"\n",
    "    def __init__(self, X, W, b):\n",
    "        # The base class (Node) constructor. Weights and bias\n",
    "        # are treated like inbound nodes.\n",
    "        Node.__init__(self, [X, W, b])\n",
    "\n",
    "    def forward(self):\n",
    "        \"\"\"\n",
    "        Performs the math behind a linear transform.\n",
    "        \"\"\"\n",
    "        X = self.inbound_nodes[0].value\n",
    "        W = self.inbound_nodes[1].value\n",
    "        b = self.inbound_nodes[2].value\n",
    "        self.value = np.dot(X, W) + b\n",
    "\n",
    "    def backward(self):\n",
    "        \"\"\"\n",
    "        Calculates the gradient based on the output values.\n",
    "        \"\"\"\n",
    "        # Initialize a partial for each of the inbound_nodes.\n",
    "        self.gradients = {n: np.zeros_like(n.value) for n in self.inbound_nodes}\n",
    "        # Cycle through the outputs. The gradient will change depending\n",
    "        # on each output, so the gradients are summed over all outputs.\n",
    "        for n in self.outbound_nodes:\n",
    "            # Get the partial of the cost with respect to this node.\n",
    "            grad_cost = n.gradients[self]\n",
    "            # Set the partial of the loss with respect to this node's inputs.\n",
    "            self.gradients[self.inbound_nodes[0]] += np.dot(grad_cost, self.inbound_nodes[1].value.T)\n",
    "            # Set the partial of the loss with respect to this node's weights.\n",
    "            self.gradients[self.inbound_nodes[1]] += np.dot(self.inbound_nodes[0].value.T, grad_cost)\n",
    "            # Set the partial of the loss with respect to this node's bias.\n",
    "            self.gradients[self.inbound_nodes[2]] += np.sum(grad_cost, axis=0, keepdims=False)\n",
    "\n",
    "\n",
    "class Sigmoid(Node):\n",
    "    \"\"\"\n",
    "    Represents a node that performs the sigmoid activation function.\n",
    "    \"\"\"\n",
    "    def __init__(self, node):\n",
    "        # The base class constructor.\n",
    "        Node.__init__(self, [node])\n",
    "\n",
    "    def _sigmoid(self, x):\n",
    "        \"\"\"\n",
    "        This method is separate from `forward` because it\n",
    "        will be used with `backward` as well.\n",
    "\n",
    "        `x`: A numpy array-like object.\n",
    "        \"\"\"\n",
    "        return 1. / (1. + np.exp(-x))\n",
    "\n",
    "    def forward(self):\n",
    "        \"\"\"\n",
    "        Perform the sigmoid function and set the value.\n",
    "        \"\"\"\n",
    "        input_value = self.inbound_nodes[0].value\n",
    "        self.value = self._sigmoid(input_value)\n",
    "\n",
    "    def backward(self):\n",
    "        \"\"\"\n",
    "        Calculates the gradient using the derivative of\n",
    "        the sigmoid function.\n",
    "        \"\"\"\n",
    "        # Initialize the gradients to 0.\n",
    "        self.gradients = {n: np.zeros_like(n.value) for n in self.inbound_nodes}\n",
    "        # Sum the partial with respect to the input over all the outputs.\n",
    "        for n in self.outbound_nodes:\n",
    "            grad_cost = n.gradients[self]\n",
    "            sigmoid = self.value\n",
    "            self.gradients[self.inbound_nodes[0]] += sigmoid * (1 - sigmoid) * grad_cost\n",
    "\n",
    "\n",
    "class MSE(Node):\n",
    "    def __init__(self, y, a):\n",
    "        \"\"\"\n",
    "        The mean squared error cost function.\n",
    "        Should be used as the last node for a network.\n",
    "        \"\"\"\n",
    "        # Call the base class' constructor.\n",
    "        Node.__init__(self, [y, a])\n",
    "\n",
    "    def forward(self):\n",
    "        \"\"\"\n",
    "        Calculates the mean squared error.\n",
    "        \"\"\"\n",
    "        # NOTE: We reshape these to avoid possible matrix/vector broadcast\n",
    "        # errors.\n",
    "        #\n",
    "        # For example, if we subtract an array of shape (3,) from an array of shape\n",
    "        # (3,1) we get an array of shape(3,3) as the result when we want\n",
    "        # an array of shape (3,1) instead.\n",
    "        #\n",
    "        # Making both arrays (3,1) insures the result is (3,1) and does\n",
    "        # an elementwise subtraction as expected.\n",
    "        y = self.inbound_nodes[0].value.reshape(-1, 1)\n",
    "        a = self.inbound_nodes[1].value.reshape(-1, 1)\n",
    "\n",
    "        self.m = self.inbound_nodes[0].value.shape[0]\n",
    "        # Save the computed output for backward.\n",
    "        self.diff = y - a\n",
    "        self.value = np.mean(self.diff**2)\n",
    "\n",
    "    def backward(self):\n",
    "        \"\"\"\n",
    "        Calculates the gradient of the cost.\n",
    "        \"\"\"\n",
    "        self.gradients[self.inbound_nodes[0]] = (2 / self.m) * self.diff\n",
    "        self.gradients[self.inbound_nodes[1]] = (-2 / self.m) * self.diff\n",
    "\n",
    "\n",
    "def topological_sort(feed_dict):\n",
    "    \"\"\"\n",
    "    Sort the nodes in topological order using Kahn's Algorithm.\n",
    "\n",
    "    `feed_dict`: A dictionary where the key is a `Input` Node and the value is the respective value feed to that Node.\n",
    "\n",
    "    Returns a list of sorted nodes.\n",
    "    \"\"\"\n",
    "\n",
    "    input_nodes = [n for n in feed_dict.keys()]\n",
    "\n",
    "    G = {}\n",
    "    nodes = [n for n in input_nodes]\n",
    "    while len(nodes) > 0:\n",
    "        n = nodes.pop(0)\n",
    "        if n not in G:\n",
    "            G[n] = {'in': set(), 'out': set()}\n",
    "        for m in n.outbound_nodes:\n",
    "            if m not in G:\n",
    "                G[m] = {'in': set(), 'out': set()}\n",
    "            G[n]['out'].add(m)\n",
    "            G[m]['in'].add(n)\n",
    "            nodes.append(m)\n",
    "\n",
    "    L = []\n",
    "    S = set(input_nodes)\n",
    "    while len(S) > 0:\n",
    "        n = S.pop()\n",
    "\n",
    "        if isinstance(n, Input):\n",
    "            n.value = feed_dict[n]\n",
    "\n",
    "        L.append(n)\n",
    "        for m in n.outbound_nodes:\n",
    "            G[n]['out'].remove(m)\n",
    "            G[m]['in'].remove(n)\n",
    "            # if no other incoming edges add to S\n",
    "            if len(G[m]['in']) == 0:\n",
    "                S.add(m)\n",
    "    return L\n",
    "\n",
    "\n",
    "def forward_and_backward(graph):\n",
    "    \"\"\"\n",
    "    Performs a forward pass and a backward pass through a list of sorted Nodes.\n",
    "\n",
    "    Arguments:\n",
    "\n",
    "        `graph`: The result of calling `topological_sort`.\n",
    "    \"\"\"\n",
    "    # Forward pass\n",
    "    for n in graph:\n",
    "        n.forward()\n",
    "\n",
    "    # Backward pass\n",
    "    # see: https://docs.python.org/2.3/whatsnew/section-slices.html\n",
    "    for n in graph[::-1]:\n",
    "        n.backward()\n",
    "\n",
    "\n",
    "def sgd_update(trainables, learning_rate=0.01):\n",
    "    \"\"\"\n",
    "    Updates the value of each trainable with SGD.\n",
    "\n",
    "    Arguments:\n",
    "\n",
    "        `trainables`: A list of `Input` Nodes representing weights/biases.\n",
    "        `learning_rate`: The learning rate.\n",
    "    \"\"\"\n",
    "    # Performs SGD\n",
    "    #\n",
    "    # Loop over the trainables\n",
    "    for t in trainables:\n",
    "        # Change the trainable's value by subtracting the learning rate\n",
    "        # multiplied by the partial of the cost with respect to this\n",
    "        # trainable.\n",
    "        partial = t.gradients[t]\n",
    "        t.value -= learning_rate * partial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of examples = 68\n",
      "Epoch: 1, Loss: 753832870.517\n",
      "Epoch: 2, Loss: 58566133.026\n",
      "Epoch: 3, Loss: 68331278.873\n",
      "Epoch: 4, Loss: 62719260.674\n",
      "Epoch: 5, Loss: 60281638.961\n",
      "Epoch: 6, Loss: 75827807.739\n",
      "Epoch: 7, Loss: 76850041.034\n",
      "Epoch: 8, Loss: 61236388.944\n",
      "Epoch: 9, Loss: 42469710.786\n",
      "Epoch: 10, Loss: 70743814.511\n",
      "Epoch: 11, Loss: 53369872.800\n",
      "Epoch: 12, Loss: 56521814.130\n",
      "Epoch: 13, Loss: 63879183.217\n",
      "Epoch: 14, Loss: 59590639.862\n",
      "Epoch: 15, Loss: 43540356.766\n",
      "Epoch: 16, Loss: 67047433.005\n",
      "Epoch: 17, Loss: 47355019.745\n",
      "Epoch: 18, Loss: 68195432.224\n",
      "Epoch: 19, Loss: 64788992.442\n",
      "Epoch: 20, Loss: 69774192.156\n",
      "Epoch: 21, Loss: 65822462.140\n",
      "Epoch: 22, Loss: 52594395.004\n",
      "Epoch: 23, Loss: 56368508.902\n",
      "Epoch: 24, Loss: 56104104.190\n",
      "Epoch: 25, Loss: 61420688.700\n",
      "Epoch: 26, Loss: 47245435.001\n",
      "Epoch: 27, Loss: 41891229.045\n",
      "Epoch: 28, Loss: 52460027.914\n",
      "Epoch: 29, Loss: 54693393.379\n",
      "Epoch: 30, Loss: 55904471.414\n",
      "Epoch: 31, Loss: 54488577.997\n",
      "Epoch: 32, Loss: 67362826.654\n",
      "Epoch: 33, Loss: 67359648.687\n",
      "Epoch: 34, Loss: 50442003.993\n",
      "Epoch: 35, Loss: 59069527.874\n",
      "Epoch: 36, Loss: 59660372.126\n",
      "Epoch: 37, Loss: 59498065.601\n",
      "Epoch: 38, Loss: 60355798.444\n",
      "Epoch: 39, Loss: 58163822.840\n",
      "Epoch: 40, Loss: 68386229.297\n",
      "Epoch: 41, Loss: 57089097.422\n",
      "Epoch: 42, Loss: 62808994.406\n",
      "Epoch: 43, Loss: 57814122.203\n",
      "Epoch: 44, Loss: 55557502.657\n",
      "Epoch: 45, Loss: 61578509.947\n",
      "Epoch: 46, Loss: 53897612.117\n",
      "Epoch: 47, Loss: 60523199.201\n",
      "Epoch: 48, Loss: 72081135.267\n",
      "Epoch: 49, Loss: 54367540.055\n",
      "Epoch: 50, Loss: 53726879.842\n",
      "Epoch: 51, Loss: 49922594.117\n",
      "Epoch: 52, Loss: 57603084.011\n",
      "Epoch: 53, Loss: 57292650.099\n",
      "Epoch: 54, Loss: 63834800.886\n",
      "Epoch: 55, Loss: 55832443.079\n",
      "Epoch: 56, Loss: 60983116.729\n",
      "Epoch: 57, Loss: 53640477.793\n",
      "Epoch: 58, Loss: 47809926.438\n",
      "Epoch: 59, Loss: 64411489.927\n",
      "Epoch: 60, Loss: 63257215.689\n",
      "Epoch: 61, Loss: 63054996.146\n",
      "Epoch: 62, Loss: 58200205.113\n",
      "Epoch: 63, Loss: 69785036.689\n",
      "Epoch: 64, Loss: 58814718.557\n",
      "Epoch: 65, Loss: 67458610.130\n",
      "Epoch: 66, Loss: 64002210.781\n",
      "Epoch: 67, Loss: 51188801.695\n",
      "Epoch: 68, Loss: 70017176.367\n",
      "Epoch: 69, Loss: 58733160.588\n",
      "Epoch: 70, Loss: 54715644.939\n",
      "Epoch: 71, Loss: 68319409.888\n",
      "Epoch: 72, Loss: 61304785.769\n",
      "Epoch: 73, Loss: 62293770.158\n",
      "Epoch: 74, Loss: 65779266.562\n",
      "Epoch: 75, Loss: 59249023.069\n",
      "Epoch: 76, Loss: 66184917.942\n",
      "Epoch: 77, Loss: 53230403.249\n",
      "Epoch: 78, Loss: 59989249.168\n",
      "Epoch: 79, Loss: 67270310.545\n",
      "Epoch: 80, Loss: 57997082.311\n",
      "Epoch: 81, Loss: 64645754.835\n",
      "Epoch: 82, Loss: 60110160.909\n",
      "Epoch: 83, Loss: 67211831.999\n",
      "Epoch: 84, Loss: 61691929.403\n",
      "Epoch: 85, Loss: 61102443.965\n",
      "Epoch: 86, Loss: 65575518.963\n",
      "Epoch: 87, Loss: 62612980.354\n",
      "Epoch: 88, Loss: 67810521.208\n",
      "Epoch: 89, Loss: 62521057.493\n",
      "Epoch: 90, Loss: 62868923.047\n",
      "Epoch: 91, Loss: 52849965.344\n",
      "Epoch: 92, Loss: 64872917.183\n",
      "Epoch: 93, Loss: 60671307.613\n",
      "Epoch: 94, Loss: 50813647.174\n",
      "Epoch: 95, Loss: 58503744.394\n",
      "Epoch: 96, Loss: 63943820.422\n",
      "Epoch: 97, Loss: 71185964.890\n",
      "Epoch: 98, Loss: 60218090.236\n",
      "Epoch: 99, Loss: 51070823.696\n",
      "Epoch: 100, Loss: 57484711.867\n",
      "Epoch: 101, Loss: 69047720.610\n",
      "Epoch: 102, Loss: 50800002.677\n",
      "Epoch: 103, Loss: 61070886.645\n",
      "Epoch: 104, Loss: 56715351.415\n",
      "Epoch: 105, Loss: 66888211.774\n",
      "Epoch: 106, Loss: 67549657.137\n",
      "Epoch: 107, Loss: 65443111.113\n",
      "Epoch: 108, Loss: 62451357.910\n",
      "Epoch: 109, Loss: 51136857.596\n",
      "Epoch: 110, Loss: 65680197.050\n",
      "Epoch: 111, Loss: 59402687.876\n",
      "Epoch: 112, Loss: 49913634.101\n",
      "Epoch: 113, Loss: 57850902.279\n",
      "Epoch: 114, Loss: 74964657.791\n",
      "Epoch: 115, Loss: 71595063.471\n",
      "Epoch: 116, Loss: 53348253.254\n",
      "Epoch: 117, Loss: 49938699.461\n",
      "Epoch: 118, Loss: 63128972.234\n",
      "Epoch: 119, Loss: 51257533.216\n",
      "Epoch: 120, Loss: 60988691.943\n",
      "Epoch: 121, Loss: 70148070.955\n",
      "Epoch: 122, Loss: 62096043.074\n",
      "Epoch: 123, Loss: 65715736.209\n",
      "Epoch: 124, Loss: 56059538.577\n",
      "Epoch: 125, Loss: 67174824.072\n",
      "Epoch: 126, Loss: 61581448.968\n",
      "Epoch: 127, Loss: 67251017.593\n",
      "Epoch: 128, Loss: 47341177.143\n",
      "Epoch: 129, Loss: 56644036.899\n",
      "Epoch: 130, Loss: 62375289.445\n",
      "Epoch: 131, Loss: 49376349.321\n",
      "Epoch: 132, Loss: 66789272.691\n",
      "Epoch: 133, Loss: 63277188.887\n",
      "Epoch: 134, Loss: 61920092.701\n",
      "Epoch: 135, Loss: 57938003.228\n",
      "Epoch: 136, Loss: 74342764.333\n",
      "Epoch: 137, Loss: 53446150.860\n",
      "Epoch: 138, Loss: 76467702.683\n",
      "Epoch: 139, Loss: 65645082.924\n",
      "Epoch: 140, Loss: 54359330.588\n",
      "Epoch: 141, Loss: 53256876.269\n",
      "Epoch: 142, Loss: 61923409.688\n",
      "Epoch: 143, Loss: 62518723.000\n",
      "Epoch: 144, Loss: 59244730.295\n",
      "Epoch: 145, Loss: 65162210.365\n",
      "Epoch: 146, Loss: 64252746.117\n",
      "Epoch: 147, Loss: 63958014.690\n",
      "Epoch: 148, Loss: 55188589.639\n",
      "Epoch: 149, Loss: 60980628.991\n",
      "Epoch: 150, Loss: 65167630.736\n",
      "Epoch: 151, Loss: 60183179.244\n",
      "Epoch: 152, Loss: 55509241.893\n",
      "Epoch: 153, Loss: 64038095.288\n",
      "Epoch: 154, Loss: 51345801.320\n",
      "Epoch: 155, Loss: 53067776.326\n",
      "Epoch: 156, Loss: 59717582.403\n",
      "Epoch: 157, Loss: 68529108.227\n",
      "Epoch: 158, Loss: 64215103.917\n",
      "Epoch: 159, Loss: 64437747.027\n",
      "Epoch: 160, Loss: 66382153.472\n",
      "Epoch: 161, Loss: 60970020.491\n",
      "Epoch: 162, Loss: 45499224.756\n",
      "Epoch: 163, Loss: 52359883.068\n",
      "Epoch: 164, Loss: 70333068.273\n",
      "Epoch: 165, Loss: 59716086.224\n",
      "Epoch: 166, Loss: 54784412.195\n",
      "Epoch: 167, Loss: 67330351.229\n",
      "Epoch: 168, Loss: 53644105.811\n",
      "Epoch: 169, Loss: 63028659.960\n",
      "Epoch: 170, Loss: 65216354.688\n",
      "Epoch: 171, Loss: 61102923.934\n",
      "Epoch: 172, Loss: 66383996.944\n",
      "Epoch: 173, Loss: 65409299.729\n",
      "Epoch: 174, Loss: 61880791.647\n",
      "Epoch: 175, Loss: 61659018.658\n",
      "Epoch: 176, Loss: 57784204.267\n",
      "Epoch: 177, Loss: 70573096.899\n",
      "Epoch: 178, Loss: 62335470.858\n",
      "Epoch: 179, Loss: 71649774.240\n",
      "Epoch: 180, Loss: 65335316.421\n",
      "Epoch: 181, Loss: 46834857.786\n",
      "Epoch: 182, Loss: 53498327.461\n",
      "Epoch: 183, Loss: 52970763.286\n",
      "Epoch: 184, Loss: 61683254.475\n",
      "Epoch: 185, Loss: 48707393.641\n",
      "Epoch: 186, Loss: 64916990.034\n",
      "Epoch: 187, Loss: 50806132.494\n",
      "Epoch: 188, Loss: 61580798.654\n",
      "Epoch: 189, Loss: 65072163.043\n",
      "Epoch: 190, Loss: 52211135.646\n",
      "Epoch: 191, Loss: 50631099.673\n",
      "Epoch: 192, Loss: 63081848.215\n",
      "Epoch: 193, Loss: 48740518.465\n",
      "Epoch: 194, Loss: 68434496.628\n",
      "Epoch: 195, Loss: 57975181.862\n",
      "Epoch: 196, Loss: 54977587.249\n",
      "Epoch: 197, Loss: 68455977.713\n",
      "Epoch: 198, Loss: 54452185.452\n",
      "Epoch: 199, Loss: 68990521.332\n",
      "Epoch: 200, Loss: 65351885.331\n",
      "Epoch: 201, Loss: 53701955.655\n",
      "Epoch: 202, Loss: 64892341.558\n",
      "Epoch: 203, Loss: 50280716.955\n",
      "Epoch: 204, Loss: 57930299.070\n",
      "Epoch: 205, Loss: 55315954.912\n",
      "Epoch: 206, Loss: 45863533.534\n",
      "Epoch: 207, Loss: 60249819.236\n",
      "Epoch: 208, Loss: 56775653.478\n",
      "Epoch: 209, Loss: 51962915.683\n",
      "Epoch: 210, Loss: 62171676.532\n",
      "Epoch: 211, Loss: 66853322.952\n",
      "Epoch: 212, Loss: 65669807.081\n",
      "Epoch: 213, Loss: 68121376.954\n",
      "Epoch: 214, Loss: 60306448.252\n",
      "Epoch: 215, Loss: 69032694.317\n",
      "Epoch: 216, Loss: 62364748.661\n",
      "Epoch: 217, Loss: 61026082.947\n",
      "Epoch: 218, Loss: 56459159.826\n",
      "Epoch: 219, Loss: 50607334.442\n",
      "Epoch: 220, Loss: 49946661.646\n",
      "Epoch: 221, Loss: 57519035.120\n",
      "Epoch: 222, Loss: 61822920.730\n",
      "Epoch: 223, Loss: 58391857.899\n",
      "Epoch: 224, Loss: 56352466.961\n",
      "Epoch: 225, Loss: 65874453.105\n",
      "Epoch: 226, Loss: 62599233.280\n",
      "Epoch: 227, Loss: 64695422.572\n",
      "Epoch: 228, Loss: 60444379.218\n",
      "Epoch: 229, Loss: 46915293.433\n",
      "Epoch: 230, Loss: 54487632.073\n",
      "Epoch: 231, Loss: 61981080.882\n",
      "Epoch: 232, Loss: 58487630.036\n",
      "Epoch: 233, Loss: 54840089.139\n",
      "Epoch: 234, Loss: 53920000.705\n",
      "Epoch: 235, Loss: 52866115.542\n",
      "Epoch: 236, Loss: 56537846.365\n",
      "Epoch: 237, Loss: 58320528.625\n",
      "Epoch: 238, Loss: 64909351.173\n",
      "Epoch: 239, Loss: 63810107.708\n",
      "Epoch: 240, Loss: 38538921.930\n",
      "Epoch: 241, Loss: 61889773.161\n",
      "Epoch: 242, Loss: 56111844.714\n",
      "Epoch: 243, Loss: 45614776.029\n",
      "Epoch: 244, Loss: 61930453.282\n",
      "Epoch: 245, Loss: 47473880.384\n",
      "Epoch: 246, Loss: 77873508.822\n",
      "Epoch: 247, Loss: 62316975.804\n",
      "Epoch: 248, Loss: 55104963.771\n",
      "Epoch: 249, Loss: 58951336.958\n",
      "Epoch: 250, Loss: 65747055.099\n",
      "Epoch: 251, Loss: 51988341.672\n",
      "Epoch: 252, Loss: 59244111.788\n",
      "Epoch: 253, Loss: 57539476.017\n",
      "Epoch: 254, Loss: 52169812.323\n",
      "Epoch: 255, Loss: 52250241.272\n",
      "Epoch: 256, Loss: 49059667.388\n",
      "Epoch: 257, Loss: 65723031.833\n",
      "Epoch: 258, Loss: 53756188.457\n",
      "Epoch: 259, Loss: 56666419.087\n",
      "Epoch: 260, Loss: 59805167.407\n",
      "Epoch: 261, Loss: 64510660.157\n",
      "Epoch: 262, Loss: 56849966.720\n",
      "Epoch: 263, Loss: 56622562.556\n",
      "Epoch: 264, Loss: 62571674.661\n",
      "Epoch: 265, Loss: 61286106.089\n",
      "Epoch: 266, Loss: 61502319.857\n",
      "Epoch: 267, Loss: 66217049.159\n",
      "Epoch: 268, Loss: 62100039.805\n",
      "Epoch: 269, Loss: 67055237.688\n",
      "Epoch: 270, Loss: 57894538.784\n",
      "Epoch: 271, Loss: 53298806.538\n",
      "Epoch: 272, Loss: 65565460.089\n",
      "Epoch: 273, Loss: 49796477.879\n",
      "Epoch: 274, Loss: 41747024.672\n",
      "Epoch: 275, Loss: 48849068.901\n",
      "Epoch: 276, Loss: 53667233.348\n",
      "Epoch: 277, Loss: 52133393.250\n",
      "Epoch: 278, Loss: 64149695.243\n",
      "Epoch: 279, Loss: 55943531.921\n",
      "Epoch: 280, Loss: 57298690.874\n",
      "Epoch: 281, Loss: 64101684.338\n",
      "Epoch: 282, Loss: 60824946.250\n",
      "Epoch: 283, Loss: 73426038.515\n",
      "Epoch: 284, Loss: 55103022.209\n",
      "Epoch: 285, Loss: 53676021.204\n",
      "Epoch: 286, Loss: 62117028.753\n",
      "Epoch: 287, Loss: 65859550.632\n",
      "Epoch: 288, Loss: 62190264.853\n",
      "Epoch: 289, Loss: 47871576.157\n",
      "Epoch: 290, Loss: 63105075.073\n",
      "Epoch: 291, Loss: 50768604.690\n",
      "Epoch: 292, Loss: 56689782.971\n",
      "Epoch: 293, Loss: 65087706.989\n",
      "Epoch: 294, Loss: 64824454.961\n",
      "Epoch: 295, Loss: 60690655.646\n",
      "Epoch: 296, Loss: 63875707.018\n",
      "Epoch: 297, Loss: 61054213.273\n",
      "Epoch: 298, Loss: 61124781.364\n",
      "Epoch: 299, Loss: 60231120.715\n",
      "Epoch: 300, Loss: 64475963.075\n",
      "Epoch: 301, Loss: 62887819.694\n",
      "Epoch: 302, Loss: 54671818.796\n",
      "Epoch: 303, Loss: 73392362.652\n",
      "Epoch: 304, Loss: 61159854.139\n",
      "Epoch: 305, Loss: 61413578.544\n",
      "Epoch: 306, Loss: 55100333.423\n",
      "Epoch: 307, Loss: 62974541.774\n",
      "Epoch: 308, Loss: 70069441.955\n",
      "Epoch: 309, Loss: 53394042.790\n",
      "Epoch: 310, Loss: 60481411.497\n",
      "Epoch: 311, Loss: 58365265.330\n",
      "Epoch: 312, Loss: 63225957.598\n",
      "Epoch: 313, Loss: 66765375.600\n",
      "Epoch: 314, Loss: 65951979.551\n",
      "Epoch: 315, Loss: 67470320.812\n",
      "Epoch: 316, Loss: 56476339.440\n",
      "Epoch: 317, Loss: 57976769.632\n",
      "Epoch: 318, Loss: 65259996.243\n",
      "Epoch: 319, Loss: 56249987.656\n",
      "Epoch: 320, Loss: 63956366.904\n",
      "Epoch: 321, Loss: 61987964.201\n",
      "Epoch: 322, Loss: 67132891.772\n",
      "Epoch: 323, Loss: 64920160.845\n",
      "Epoch: 324, Loss: 64227811.111\n",
      "Epoch: 325, Loss: 57343506.089\n",
      "Epoch: 326, Loss: 63635261.245\n",
      "Epoch: 327, Loss: 64292275.205\n",
      "Epoch: 328, Loss: 53348328.062\n",
      "Epoch: 329, Loss: 48402935.234\n",
      "Epoch: 330, Loss: 49672558.613\n",
      "Epoch: 331, Loss: 61429482.312\n",
      "Epoch: 332, Loss: 65114677.190\n",
      "Epoch: 333, Loss: 51307883.790\n",
      "Epoch: 334, Loss: 69569686.315\n",
      "Epoch: 335, Loss: 60765828.475\n",
      "Epoch: 336, Loss: 65257972.055\n",
      "Epoch: 337, Loss: 64098025.370\n",
      "Epoch: 338, Loss: 73775696.198\n",
      "Epoch: 339, Loss: 59424461.691\n",
      "Epoch: 340, Loss: 48507151.125\n",
      "Epoch: 341, Loss: 63683704.104\n",
      "Epoch: 342, Loss: 63148361.621\n",
      "Epoch: 343, Loss: 67980810.688\n",
      "Epoch: 344, Loss: 50889814.025\n",
      "Epoch: 345, Loss: 70113992.181\n",
      "Epoch: 346, Loss: 68412290.999\n",
      "Epoch: 347, Loss: 66250004.822\n",
      "Epoch: 348, Loss: 61821012.315\n",
      "Epoch: 349, Loss: 66263687.508\n",
      "Epoch: 350, Loss: 61247366.490\n",
      "Epoch: 351, Loss: 54897499.782\n",
      "Epoch: 352, Loss: 67254417.486\n",
      "Epoch: 353, Loss: 76145403.327\n",
      "Epoch: 354, Loss: 60560919.058\n",
      "Epoch: 355, Loss: 57617592.138\n",
      "Epoch: 356, Loss: 61216411.064\n",
      "Epoch: 357, Loss: 60112062.913\n",
      "Epoch: 358, Loss: 60685247.867\n",
      "Epoch: 359, Loss: 59440723.468\n",
      "Epoch: 360, Loss: 54423047.350\n",
      "Epoch: 361, Loss: 53144573.178\n",
      "Epoch: 362, Loss: 60000138.173\n",
      "Epoch: 363, Loss: 46620753.310\n",
      "Epoch: 364, Loss: 52367053.715\n",
      "Epoch: 365, Loss: 50173647.786\n",
      "Epoch: 366, Loss: 55569888.852\n",
      "Epoch: 367, Loss: 62637770.601\n",
      "Epoch: 368, Loss: 55654940.281\n",
      "Epoch: 369, Loss: 52061423.205\n",
      "Epoch: 370, Loss: 51968491.909\n",
      "Epoch: 371, Loss: 77352024.399\n",
      "Epoch: 372, Loss: 58613708.458\n",
      "Epoch: 373, Loss: 54953957.727\n",
      "Epoch: 374, Loss: 63404236.889\n",
      "Epoch: 375, Loss: 68066480.374\n",
      "Epoch: 376, Loss: 61905321.506\n",
      "Epoch: 377, Loss: 61965252.557\n",
      "Epoch: 378, Loss: 64289088.987\n",
      "Epoch: 379, Loss: 71528845.105\n",
      "Epoch: 380, Loss: 60321893.855\n",
      "Epoch: 381, Loss: 67559946.268\n",
      "Epoch: 382, Loss: 63433945.218\n",
      "Epoch: 383, Loss: 56108586.898\n",
      "Epoch: 384, Loss: 54454696.538\n",
      "Epoch: 385, Loss: 68182309.036\n",
      "Epoch: 386, Loss: 63216720.822\n",
      "Epoch: 387, Loss: 86228649.193\n",
      "Epoch: 388, Loss: 68906810.707\n",
      "Epoch: 389, Loss: 60540742.751\n",
      "Epoch: 390, Loss: 56725882.093\n",
      "Epoch: 391, Loss: 57659885.113\n",
      "Epoch: 392, Loss: 55519503.757\n",
      "Epoch: 393, Loss: 75305999.436\n",
      "Epoch: 394, Loss: 59668602.684\n",
      "Epoch: 395, Loss: 69507830.355\n",
      "Epoch: 396, Loss: 53543088.704\n",
      "Epoch: 397, Loss: 63809882.552\n",
      "Epoch: 398, Loss: 67438442.807\n",
      "Epoch: 399, Loss: 49245326.071\n",
      "Epoch: 400, Loss: 64129494.858\n",
      "Epoch: 401, Loss: 36352511.038\n",
      "Epoch: 402, Loss: 55858045.944\n",
      "Epoch: 403, Loss: 66891727.146\n",
      "Epoch: 404, Loss: 45473382.364\n",
      "Epoch: 405, Loss: 53829713.499\n",
      "Epoch: 406, Loss: 57930458.884\n",
      "Epoch: 407, Loss: 54196833.172\n",
      "Epoch: 408, Loss: 55508067.586\n",
      "Epoch: 409, Loss: 60449953.147\n",
      "Epoch: 410, Loss: 56285661.872\n",
      "Epoch: 411, Loss: 59321303.673\n",
      "Epoch: 412, Loss: 67733198.811\n",
      "Epoch: 413, Loss: 62914769.320\n",
      "Epoch: 414, Loss: 55233311.137\n",
      "Epoch: 415, Loss: 57812500.219\n",
      "Epoch: 416, Loss: 63055816.181\n",
      "Epoch: 417, Loss: 57369930.001\n",
      "Epoch: 418, Loss: 59495845.809\n",
      "Epoch: 419, Loss: 69011204.065\n",
      "Epoch: 420, Loss: 63115047.093\n",
      "Epoch: 421, Loss: 62753209.197\n",
      "Epoch: 422, Loss: 57343831.618\n",
      "Epoch: 423, Loss: 55269766.948\n",
      "Epoch: 424, Loss: 71393253.974\n",
      "Epoch: 425, Loss: 50054199.168\n",
      "Epoch: 426, Loss: 64613909.072\n",
      "Epoch: 427, Loss: 48919366.830\n",
      "Epoch: 428, Loss: 68095891.496\n",
      "Epoch: 429, Loss: 59506852.398\n",
      "Epoch: 430, Loss: 63092602.383\n",
      "Epoch: 431, Loss: 63668453.661\n",
      "Epoch: 432, Loss: 51563077.021\n",
      "Epoch: 433, Loss: 62865455.884\n",
      "Epoch: 434, Loss: 60269845.862\n",
      "Epoch: 435, Loss: 65049714.875\n",
      "Epoch: 436, Loss: 52544027.373\n",
      "Epoch: 437, Loss: 65497078.058\n",
      "Epoch: 438, Loss: 66337803.578\n",
      "Epoch: 439, Loss: 60433875.587\n",
      "Epoch: 440, Loss: 52518451.205\n",
      "Epoch: 441, Loss: 63314409.649\n",
      "Epoch: 442, Loss: 64226242.429\n",
      "Epoch: 443, Loss: 56887355.627\n",
      "Epoch: 444, Loss: 50780038.385\n",
      "Epoch: 445, Loss: 59529577.850\n",
      "Epoch: 446, Loss: 52704839.205\n",
      "Epoch: 447, Loss: 57943020.489\n",
      "Epoch: 448, Loss: 56912123.091\n",
      "Epoch: 449, Loss: 64970834.167\n",
      "Epoch: 450, Loss: 59220009.510\n",
      "Epoch: 451, Loss: 64844088.604\n",
      "Epoch: 452, Loss: 59706496.942\n",
      "Epoch: 453, Loss: 54397242.982\n",
      "Epoch: 454, Loss: 59863093.592\n",
      "Epoch: 455, Loss: 70226490.305\n",
      "Epoch: 456, Loss: 51964920.965\n",
      "Epoch: 457, Loss: 69802939.975\n",
      "Epoch: 458, Loss: 66916270.869\n",
      "Epoch: 459, Loss: 52733844.767\n",
      "Epoch: 460, Loss: 58525496.989\n",
      "Epoch: 461, Loss: 59193282.943\n",
      "Epoch: 462, Loss: 62526556.314\n",
      "Epoch: 463, Loss: 52677804.610\n",
      "Epoch: 464, Loss: 59390335.139\n",
      "Epoch: 465, Loss: 66212047.961\n",
      "Epoch: 466, Loss: 64387712.659\n",
      "Epoch: 467, Loss: 66727575.868\n",
      "Epoch: 468, Loss: 41903201.361\n",
      "Epoch: 469, Loss: 50623131.031\n",
      "Epoch: 470, Loss: 65141002.350\n",
      "Epoch: 471, Loss: 58681606.724\n",
      "Epoch: 472, Loss: 56771718.419\n",
      "Epoch: 473, Loss: 64358717.257\n",
      "Epoch: 474, Loss: 56617651.268\n",
      "Epoch: 475, Loss: 53171766.578\n",
      "Epoch: 476, Loss: 54970775.974\n",
      "Epoch: 477, Loss: 69792419.176\n",
      "Epoch: 478, Loss: 49505298.589\n",
      "Epoch: 479, Loss: 68982943.219\n",
      "Epoch: 480, Loss: 62457120.355\n",
      "Epoch: 481, Loss: 67513807.571\n",
      "Epoch: 482, Loss: 53753490.109\n",
      "Epoch: 483, Loss: 64728414.449\n",
      "Epoch: 484, Loss: 58934711.872\n",
      "Epoch: 485, Loss: 62098253.102\n",
      "Epoch: 486, Loss: 60574295.396\n",
      "Epoch: 487, Loss: 51123926.084\n",
      "Epoch: 488, Loss: 60628981.417\n",
      "Epoch: 489, Loss: 69086067.796\n",
      "Epoch: 490, Loss: 62581616.059\n",
      "Epoch: 491, Loss: 59366672.352\n",
      "Epoch: 492, Loss: 50146651.690\n",
      "Epoch: 493, Loss: 63740892.331\n",
      "Epoch: 494, Loss: 68536773.825\n",
      "Epoch: 495, Loss: 56315086.900\n",
      "Epoch: 496, Loss: 63671395.891\n",
      "Epoch: 497, Loss: 59815957.730\n",
      "Epoch: 498, Loss: 56967211.204\n",
      "Epoch: 499, Loss: 57123179.533\n",
      "Epoch: 500, Loss: 58124104.905\n",
      "Epoch: 501, Loss: 67145636.257\n",
      "Epoch: 502, Loss: 56504987.569\n",
      "Epoch: 503, Loss: 73011334.373\n",
      "Epoch: 504, Loss: 50954770.134\n",
      "Epoch: 505, Loss: 58941431.054\n",
      "Epoch: 506, Loss: 44250265.422\n",
      "Epoch: 507, Loss: 66580390.251\n",
      "Epoch: 508, Loss: 52300470.055\n",
      "Epoch: 509, Loss: 64546340.610\n",
      "Epoch: 510, Loss: 54574158.564\n",
      "Epoch: 511, Loss: 61087016.975\n",
      "Epoch: 512, Loss: 68225741.117\n",
      "Epoch: 513, Loss: 61908322.708\n",
      "Epoch: 514, Loss: 65134189.803\n",
      "Epoch: 515, Loss: 52043686.434\n",
      "Epoch: 516, Loss: 66188524.620\n",
      "Epoch: 517, Loss: 59801755.134\n",
      "Epoch: 518, Loss: 66117491.839\n",
      "Epoch: 519, Loss: 55843208.152\n",
      "Epoch: 520, Loss: 72563805.676\n",
      "Epoch: 521, Loss: 56966713.215\n",
      "Epoch: 522, Loss: 64133477.719\n",
      "Epoch: 523, Loss: 48586601.718\n",
      "Epoch: 524, Loss: 57235934.580\n",
      "Epoch: 525, Loss: 70888825.429\n",
      "Epoch: 526, Loss: 64133802.784\n",
      "Epoch: 527, Loss: 68390493.100\n",
      "Epoch: 528, Loss: 67303202.038\n",
      "Epoch: 529, Loss: 63541660.738\n",
      "Epoch: 530, Loss: 64563148.629\n",
      "Epoch: 531, Loss: 56552756.541\n",
      "Epoch: 532, Loss: 72525300.632\n",
      "Epoch: 533, Loss: 59836720.166\n",
      "Epoch: 534, Loss: 59702194.139\n",
      "Epoch: 535, Loss: 61687454.064\n",
      "Epoch: 536, Loss: 63638692.501\n",
      "Epoch: 537, Loss: 61561335.780\n",
      "Epoch: 538, Loss: 53574350.734\n",
      "Epoch: 539, Loss: 54435800.888\n",
      "Epoch: 540, Loss: 60898934.997\n",
      "Epoch: 541, Loss: 55665888.359\n",
      "Epoch: 542, Loss: 55235572.830\n",
      "Epoch: 543, Loss: 43609125.898\n",
      "Epoch: 544, Loss: 71770958.827\n",
      "Epoch: 545, Loss: 58427140.028\n",
      "Epoch: 546, Loss: 54461142.118\n",
      "Epoch: 547, Loss: 60561313.968\n",
      "Epoch: 548, Loss: 61399895.525\n",
      "Epoch: 549, Loss: 44771522.004\n",
      "Epoch: 550, Loss: 59778897.878\n",
      "Epoch: 551, Loss: 64180307.202\n",
      "Epoch: 552, Loss: 69282077.329\n",
      "Epoch: 553, Loss: 55521846.674\n",
      "Epoch: 554, Loss: 66063532.900\n",
      "Epoch: 555, Loss: 55551058.686\n",
      "Epoch: 556, Loss: 69076907.810\n",
      "Epoch: 557, Loss: 67717233.663\n",
      "Epoch: 558, Loss: 52544537.481\n",
      "Epoch: 559, Loss: 66397259.119\n",
      "Epoch: 560, Loss: 55019491.404\n",
      "Epoch: 561, Loss: 58281788.557\n",
      "Epoch: 562, Loss: 56852533.736\n",
      "Epoch: 563, Loss: 67809170.276\n",
      "Epoch: 564, Loss: 62303209.480\n",
      "Epoch: 565, Loss: 48162094.826\n",
      "Epoch: 566, Loss: 65627140.704\n",
      "Epoch: 567, Loss: 61158163.617\n",
      "Epoch: 568, Loss: 73012934.746\n",
      "Epoch: 569, Loss: 62474403.700\n",
      "Epoch: 570, Loss: 61000850.989\n",
      "Epoch: 571, Loss: 61116328.869\n",
      "Epoch: 572, Loss: 68694828.539\n",
      "Epoch: 573, Loss: 69444410.551\n",
      "Epoch: 574, Loss: 58545110.421\n",
      "Epoch: 575, Loss: 57027269.701\n",
      "Epoch: 576, Loss: 54709620.763\n",
      "Epoch: 577, Loss: 67614960.656\n",
      "Epoch: 578, Loss: 63013573.513\n",
      "Epoch: 579, Loss: 62173522.474\n",
      "Epoch: 580, Loss: 61187654.622\n",
      "Epoch: 581, Loss: 65020053.234\n",
      "Epoch: 582, Loss: 62125251.115\n",
      "Epoch: 583, Loss: 57305379.373\n",
      "Epoch: 584, Loss: 69838278.949\n",
      "Epoch: 585, Loss: 66609128.633\n",
      "Epoch: 586, Loss: 68875701.102\n",
      "Epoch: 587, Loss: 61708587.529\n",
      "Epoch: 588, Loss: 66500143.427\n",
      "Epoch: 589, Loss: 55651611.873\n",
      "Epoch: 590, Loss: 60673863.673\n",
      "Epoch: 591, Loss: 65543685.211\n",
      "Epoch: 592, Loss: 57422631.322\n",
      "Epoch: 593, Loss: 63783818.084\n",
      "Epoch: 594, Loss: 71310684.676\n",
      "Epoch: 595, Loss: 57057759.346\n",
      "Epoch: 596, Loss: 55537254.355\n",
      "Epoch: 597, Loss: 74302097.911\n",
      "Epoch: 598, Loss: 58851263.373\n",
      "Epoch: 599, Loss: 56495507.341\n",
      "Epoch: 600, Loss: 60908370.211\n",
      "Epoch: 601, Loss: 78876011.180\n",
      "Epoch: 602, Loss: 58448892.385\n",
      "Epoch: 603, Loss: 54153386.196\n",
      "Epoch: 604, Loss: 60556944.813\n",
      "Epoch: 605, Loss: 60176261.084\n",
      "Epoch: 606, Loss: 73024040.944\n",
      "Epoch: 607, Loss: 64314848.603\n",
      "Epoch: 608, Loss: 67152336.997\n",
      "Epoch: 609, Loss: 57801024.193\n",
      "Epoch: 610, Loss: 55411386.660\n",
      "Epoch: 611, Loss: 58036429.279\n",
      "Epoch: 612, Loss: 63831330.474\n",
      "Epoch: 613, Loss: 75151753.628\n",
      "Epoch: 614, Loss: 66888463.200\n",
      "Epoch: 615, Loss: 62811866.883\n",
      "Epoch: 616, Loss: 54519768.404\n",
      "Epoch: 617, Loss: 57176612.394\n",
      "Epoch: 618, Loss: 70009212.507\n",
      "Epoch: 619, Loss: 56695331.141\n",
      "Epoch: 620, Loss: 66496513.708\n",
      "Epoch: 621, Loss: 50217617.108\n",
      "Epoch: 622, Loss: 66375243.436\n",
      "Epoch: 623, Loss: 72014685.861\n",
      "Epoch: 624, Loss: 55464610.132\n",
      "Epoch: 625, Loss: 64464650.985\n",
      "Epoch: 626, Loss: 67864358.613\n",
      "Epoch: 627, Loss: 59462940.942\n",
      "Epoch: 628, Loss: 54149087.978\n",
      "Epoch: 629, Loss: 54951163.579\n",
      "Epoch: 630, Loss: 65191238.795\n",
      "Epoch: 631, Loss: 70706733.664\n",
      "Epoch: 632, Loss: 67023333.390\n",
      "Epoch: 633, Loss: 58528291.549\n",
      "Epoch: 634, Loss: 60369047.230\n",
      "Epoch: 635, Loss: 68237695.267\n",
      "Epoch: 636, Loss: 57373947.753\n",
      "Epoch: 637, Loss: 52475852.422\n",
      "Epoch: 638, Loss: 56476699.116\n",
      "Epoch: 639, Loss: 64446414.201\n",
      "Epoch: 640, Loss: 61334458.406\n",
      "Epoch: 641, Loss: 50050152.291\n",
      "Epoch: 642, Loss: 61159969.351\n",
      "Epoch: 643, Loss: 55845500.720\n",
      "Epoch: 644, Loss: 54752287.766\n",
      "Epoch: 645, Loss: 67168275.889\n",
      "Epoch: 646, Loss: 65298099.917\n",
      "Epoch: 647, Loss: 52810153.399\n",
      "Epoch: 648, Loss: 60737755.298\n",
      "Epoch: 649, Loss: 73231107.380\n",
      "Epoch: 650, Loss: 71262333.473\n",
      "Epoch: 651, Loss: 63951880.478\n",
      "Epoch: 652, Loss: 49053118.502\n",
      "Epoch: 653, Loss: 71350154.668\n",
      "Epoch: 654, Loss: 44508338.323\n",
      "Epoch: 655, Loss: 68220089.139\n",
      "Epoch: 656, Loss: 64380832.624\n",
      "Epoch: 657, Loss: 62646445.691\n",
      "Epoch: 658, Loss: 63043083.840\n",
      "Epoch: 659, Loss: 51258824.115\n",
      "Epoch: 660, Loss: 57003302.211\n",
      "Epoch: 661, Loss: 64683922.283\n",
      "Epoch: 662, Loss: 69430135.620\n",
      "Epoch: 663, Loss: 50459894.926\n",
      "Epoch: 664, Loss: 74278603.910\n",
      "Epoch: 665, Loss: 55483945.362\n",
      "Epoch: 666, Loss: 61672617.125\n",
      "Epoch: 667, Loss: 56890990.767\n",
      "Epoch: 668, Loss: 65637900.320\n",
      "Epoch: 669, Loss: 61890228.078\n",
      "Epoch: 670, Loss: 61940554.869\n",
      "Epoch: 671, Loss: 67486574.062\n",
      "Epoch: 672, Loss: 64566174.322\n",
      "Epoch: 673, Loss: 63725843.452\n",
      "Epoch: 674, Loss: 64633417.553\n",
      "Epoch: 675, Loss: 51383528.035\n",
      "Epoch: 676, Loss: 60534173.791\n",
      "Epoch: 677, Loss: 63123698.338\n",
      "Epoch: 678, Loss: 66025538.668\n",
      "Epoch: 679, Loss: 59617010.157\n",
      "Epoch: 680, Loss: 57449952.533\n",
      "Epoch: 681, Loss: 67590017.291\n",
      "Epoch: 682, Loss: 49510862.143\n",
      "Epoch: 683, Loss: 55995844.978\n",
      "Epoch: 684, Loss: 58594803.963\n",
      "Epoch: 685, Loss: 57918734.711\n",
      "Epoch: 686, Loss: 63675505.697\n",
      "Epoch: 687, Loss: 50299851.038\n",
      "Epoch: 688, Loss: 59604917.415\n",
      "Epoch: 689, Loss: 53583862.269\n",
      "Epoch: 690, Loss: 61613337.576\n",
      "Epoch: 691, Loss: 61838154.424\n",
      "Epoch: 692, Loss: 59484058.367\n",
      "Epoch: 693, Loss: 65705581.094\n",
      "Epoch: 694, Loss: 57528515.460\n",
      "Epoch: 695, Loss: 56787868.933\n",
      "Epoch: 696, Loss: 58275434.580\n",
      "Epoch: 697, Loss: 60822001.946\n",
      "Epoch: 698, Loss: 54768781.761\n",
      "Epoch: 699, Loss: 51972528.418\n",
      "Epoch: 700, Loss: 62028466.925\n",
      "Epoch: 701, Loss: 58527659.358\n",
      "Epoch: 702, Loss: 66935207.673\n",
      "Epoch: 703, Loss: 68389124.692\n",
      "Epoch: 704, Loss: 61421208.012\n",
      "Epoch: 705, Loss: 60626061.960\n",
      "Epoch: 706, Loss: 59786517.089\n",
      "Epoch: 707, Loss: 66931952.563\n",
      "Epoch: 708, Loss: 60199776.293\n",
      "Epoch: 709, Loss: 52259318.448\n",
      "Epoch: 710, Loss: 61671493.974\n",
      "Epoch: 711, Loss: 57020762.804\n",
      "Epoch: 712, Loss: 58922740.248\n",
      "Epoch: 713, Loss: 70672030.785\n",
      "Epoch: 714, Loss: 60962639.547\n",
      "Epoch: 715, Loss: 54583515.070\n",
      "Epoch: 716, Loss: 52544322.285\n",
      "Epoch: 717, Loss: 64725993.286\n",
      "Epoch: 718, Loss: 54731891.251\n",
      "Epoch: 719, Loss: 59383812.383\n",
      "Epoch: 720, Loss: 78858426.595\n",
      "Epoch: 721, Loss: 65469881.386\n",
      "Epoch: 722, Loss: 55975640.507\n",
      "Epoch: 723, Loss: 56522474.332\n",
      "Epoch: 724, Loss: 58779159.774\n",
      "Epoch: 725, Loss: 62685125.114\n",
      "Epoch: 726, Loss: 58020798.636\n",
      "Epoch: 727, Loss: 62105346.192\n",
      "Epoch: 728, Loss: 56988572.198\n",
      "Epoch: 729, Loss: 66984795.569\n",
      "Epoch: 730, Loss: 61154360.671\n",
      "Epoch: 731, Loss: 62967686.982\n",
      "Epoch: 732, Loss: 66359417.918\n",
      "Epoch: 733, Loss: 50931003.650\n",
      "Epoch: 734, Loss: 58014153.861\n",
      "Epoch: 735, Loss: 55227964.293\n",
      "Epoch: 736, Loss: 61917849.962\n",
      "Epoch: 737, Loss: 64962126.330\n",
      "Epoch: 738, Loss: 63949996.055\n",
      "Epoch: 739, Loss: 54076911.994\n",
      "Epoch: 740, Loss: 65654360.809\n",
      "Epoch: 741, Loss: 58922790.829\n",
      "Epoch: 742, Loss: 78566813.069\n",
      "Epoch: 743, Loss: 55731998.210\n",
      "Epoch: 744, Loss: 45000125.298\n",
      "Epoch: 745, Loss: 62359792.417\n",
      "Epoch: 746, Loss: 72677776.657\n",
      "Epoch: 747, Loss: 52078972.332\n",
      "Epoch: 748, Loss: 75178956.173\n",
      "Epoch: 749, Loss: 52677820.727\n",
      "Epoch: 750, Loss: 50449525.506\n",
      "Epoch: 751, Loss: 62823188.061\n",
      "Epoch: 752, Loss: 60288163.331\n",
      "Epoch: 753, Loss: 62825047.805\n",
      "Epoch: 754, Loss: 56004165.755\n",
      "Epoch: 755, Loss: 52297341.992\n",
      "Epoch: 756, Loss: 54143891.944\n",
      "Epoch: 757, Loss: 74294680.858\n",
      "Epoch: 758, Loss: 52525390.519\n",
      "Epoch: 759, Loss: 80279409.359\n",
      "Epoch: 760, Loss: 55101189.491\n",
      "Epoch: 761, Loss: 67848601.253\n",
      "Epoch: 762, Loss: 62576181.914\n",
      "Epoch: 763, Loss: 50709546.301\n",
      "Epoch: 764, Loss: 55354330.588\n",
      "Epoch: 765, Loss: 64854749.985\n",
      "Epoch: 766, Loss: 56979291.574\n",
      "Epoch: 767, Loss: 68997173.343\n",
      "Epoch: 768, Loss: 57991797.254\n",
      "Epoch: 769, Loss: 55589553.808\n",
      "Epoch: 770, Loss: 60734782.664\n",
      "Epoch: 771, Loss: 58033708.119\n",
      "Epoch: 772, Loss: 55671948.421\n",
      "Epoch: 773, Loss: 73226669.708\n",
      "Epoch: 774, Loss: 71517296.988\n",
      "Epoch: 775, Loss: 63590822.894\n",
      "Epoch: 776, Loss: 69815596.550\n",
      "Epoch: 777, Loss: 67462145.788\n",
      "Epoch: 778, Loss: 63593527.487\n",
      "Epoch: 779, Loss: 52996526.394\n",
      "Epoch: 780, Loss: 57744649.954\n",
      "Epoch: 781, Loss: 57752843.163\n",
      "Epoch: 782, Loss: 69452235.721\n",
      "Epoch: 783, Loss: 53916566.596\n",
      "Epoch: 784, Loss: 75425630.689\n",
      "Epoch: 785, Loss: 63211370.291\n",
      "Epoch: 786, Loss: 59839257.495\n",
      "Epoch: 787, Loss: 63826397.355\n",
      "Epoch: 788, Loss: 56427588.081\n",
      "Epoch: 789, Loss: 49094448.535\n",
      "Epoch: 790, Loss: 67524146.558\n",
      "Epoch: 791, Loss: 53164013.669\n",
      "Epoch: 792, Loss: 50289429.016\n",
      "Epoch: 793, Loss: 56272937.055\n",
      "Epoch: 794, Loss: 57658725.851\n",
      "Epoch: 795, Loss: 62672466.585\n",
      "Epoch: 796, Loss: 54400127.657\n",
      "Epoch: 797, Loss: 64753763.433\n",
      "Epoch: 798, Loss: 61057103.111\n",
      "Epoch: 799, Loss: 65527525.253\n",
      "Epoch: 800, Loss: 47507982.809\n",
      "Epoch: 801, Loss: 56081888.744\n",
      "Epoch: 802, Loss: 54154278.530\n",
      "Epoch: 803, Loss: 54262058.932\n",
      "Epoch: 804, Loss: 55401976.375\n",
      "Epoch: 805, Loss: 57754684.312\n",
      "Epoch: 806, Loss: 71909208.848\n",
      "Epoch: 807, Loss: 55257516.389\n",
      "Epoch: 808, Loss: 64738168.314\n",
      "Epoch: 809, Loss: 72801951.419\n",
      "Epoch: 810, Loss: 64149817.459\n",
      "Epoch: 811, Loss: 51107817.878\n",
      "Epoch: 812, Loss: 55532645.417\n",
      "Epoch: 813, Loss: 70410139.375\n",
      "Epoch: 814, Loss: 54229205.643\n",
      "Epoch: 815, Loss: 74416635.229\n",
      "Epoch: 816, Loss: 49955038.178\n",
      "Epoch: 817, Loss: 67102524.088\n",
      "Epoch: 818, Loss: 42821617.672\n",
      "Epoch: 819, Loss: 60667452.553\n",
      "Epoch: 820, Loss: 56862394.911\n",
      "Epoch: 821, Loss: 72177635.501\n",
      "Epoch: 822, Loss: 52237035.547\n",
      "Epoch: 823, Loss: 66383903.327\n",
      "Epoch: 824, Loss: 61516650.935\n",
      "Epoch: 825, Loss: 51105582.719\n",
      "Epoch: 826, Loss: 47843569.611\n",
      "Epoch: 827, Loss: 54367565.785\n",
      "Epoch: 828, Loss: 46385599.955\n",
      "Epoch: 829, Loss: 50510017.751\n",
      "Epoch: 830, Loss: 67203530.379\n",
      "Epoch: 831, Loss: 64954790.526\n",
      "Epoch: 832, Loss: 66507157.130\n",
      "Epoch: 833, Loss: 59205473.789\n",
      "Epoch: 834, Loss: 55857867.121\n",
      "Epoch: 835, Loss: 56562850.967\n",
      "Epoch: 836, Loss: 64807145.522\n",
      "Epoch: 837, Loss: 58775896.291\n",
      "Epoch: 838, Loss: 58576030.694\n",
      "Epoch: 839, Loss: 53434076.038\n",
      "Epoch: 840, Loss: 48327506.793\n",
      "Epoch: 841, Loss: 55858449.332\n",
      "Epoch: 842, Loss: 52294024.071\n",
      "Epoch: 843, Loss: 62449062.636\n",
      "Epoch: 844, Loss: 62534951.024\n",
      "Epoch: 845, Loss: 64439804.677\n",
      "Epoch: 846, Loss: 43835709.067\n",
      "Epoch: 847, Loss: 49499051.644\n",
      "Epoch: 848, Loss: 56769750.013\n",
      "Epoch: 849, Loss: 58506402.406\n",
      "Epoch: 850, Loss: 55456912.809\n",
      "Epoch: 851, Loss: 72558250.401\n",
      "Epoch: 852, Loss: 53042157.732\n",
      "Epoch: 853, Loss: 59751276.754\n",
      "Epoch: 854, Loss: 65849504.781\n",
      "Epoch: 855, Loss: 65267324.645\n",
      "Epoch: 856, Loss: 64359593.379\n",
      "Epoch: 857, Loss: 60187491.997\n",
      "Epoch: 858, Loss: 54207476.328\n",
      "Epoch: 859, Loss: 65271041.161\n",
      "Epoch: 860, Loss: 71099271.096\n",
      "Epoch: 861, Loss: 67596231.349\n",
      "Epoch: 862, Loss: 56039818.240\n",
      "Epoch: 863, Loss: 64710052.688\n",
      "Epoch: 864, Loss: 60995694.988\n",
      "Epoch: 865, Loss: 61990026.145\n",
      "Epoch: 866, Loss: 58831730.286\n",
      "Epoch: 867, Loss: 55744741.281\n",
      "Epoch: 868, Loss: 57977945.015\n",
      "Epoch: 869, Loss: 60115624.925\n",
      "Epoch: 870, Loss: 58356397.168\n",
      "Epoch: 871, Loss: 58572106.969\n",
      "Epoch: 872, Loss: 56035101.877\n",
      "Epoch: 873, Loss: 55980404.251\n",
      "Epoch: 874, Loss: 58695115.220\n",
      "Epoch: 875, Loss: 63006920.978\n",
      "Epoch: 876, Loss: 71734185.636\n",
      "Epoch: 877, Loss: 59528498.751\n",
      "Epoch: 878, Loss: 66035011.336\n",
      "Epoch: 879, Loss: 56996877.989\n",
      "Epoch: 880, Loss: 64106399.914\n",
      "Epoch: 881, Loss: 63120680.703\n",
      "Epoch: 882, Loss: 58730806.065\n",
      "Epoch: 883, Loss: 64226558.319\n",
      "Epoch: 884, Loss: 58153105.227\n",
      "Epoch: 885, Loss: 62867168.098\n",
      "Epoch: 886, Loss: 66260519.568\n",
      "Epoch: 887, Loss: 54358296.605\n",
      "Epoch: 888, Loss: 59718343.037\n",
      "Epoch: 889, Loss: 60757289.504\n",
      "Epoch: 890, Loss: 53175734.935\n",
      "Epoch: 891, Loss: 62373372.346\n",
      "Epoch: 892, Loss: 56058143.137\n",
      "Epoch: 893, Loss: 62418483.914\n",
      "Epoch: 894, Loss: 63393740.813\n",
      "Epoch: 895, Loss: 53599746.789\n",
      "Epoch: 896, Loss: 57327748.138\n",
      "Epoch: 897, Loss: 57797263.090\n",
      "Epoch: 898, Loss: 46943436.924\n",
      "Epoch: 899, Loss: 65374781.874\n",
      "Epoch: 900, Loss: 56919969.901\n",
      "Epoch: 901, Loss: 57724030.886\n",
      "Epoch: 902, Loss: 66766994.623\n",
      "Epoch: 903, Loss: 67466684.454\n",
      "Epoch: 904, Loss: 61051854.892\n",
      "Epoch: 905, Loss: 65981351.203\n",
      "Epoch: 906, Loss: 57593563.565\n",
      "Epoch: 907, Loss: 55010686.739\n",
      "Epoch: 908, Loss: 57432140.344\n",
      "Epoch: 909, Loss: 58523263.402\n",
      "Epoch: 910, Loss: 57348734.183\n",
      "Epoch: 911, Loss: 61287051.655\n",
      "Epoch: 912, Loss: 69941928.179\n",
      "Epoch: 913, Loss: 64087513.670\n",
      "Epoch: 914, Loss: 59170680.878\n",
      "Epoch: 915, Loss: 61436661.887\n",
      "Epoch: 916, Loss: 56033423.636\n",
      "Epoch: 917, Loss: 61537845.396\n",
      "Epoch: 918, Loss: 59112814.975\n",
      "Epoch: 919, Loss: 50654784.027\n",
      "Epoch: 920, Loss: 56833896.019\n",
      "Epoch: 921, Loss: 58539037.507\n",
      "Epoch: 922, Loss: 64622794.034\n",
      "Epoch: 923, Loss: 60711927.792\n",
      "Epoch: 924, Loss: 57657198.078\n",
      "Epoch: 925, Loss: 61537598.148\n",
      "Epoch: 926, Loss: 55673002.773\n",
      "Epoch: 927, Loss: 68355638.163\n",
      "Epoch: 928, Loss: 41401487.426\n",
      "Epoch: 929, Loss: 57747491.739\n",
      "Epoch: 930, Loss: 52773273.016\n",
      "Epoch: 931, Loss: 51694207.945\n",
      "Epoch: 932, Loss: 57253727.881\n",
      "Epoch: 933, Loss: 59330474.105\n",
      "Epoch: 934, Loss: 54082601.347\n",
      "Epoch: 935, Loss: 67061070.176\n",
      "Epoch: 936, Loss: 65763808.736\n",
      "Epoch: 937, Loss: 63290323.377\n",
      "Epoch: 938, Loss: 59385200.602\n",
      "Epoch: 939, Loss: 52907963.253\n",
      "Epoch: 940, Loss: 59323805.623\n",
      "Epoch: 941, Loss: 58989328.761\n",
      "Epoch: 942, Loss: 61209648.699\n",
      "Epoch: 943, Loss: 52973437.832\n",
      "Epoch: 944, Loss: 53795038.367\n",
      "Epoch: 945, Loss: 57272473.282\n",
      "Epoch: 946, Loss: 57929605.642\n",
      "Epoch: 947, Loss: 70151573.212\n",
      "Epoch: 948, Loss: 59289581.016\n",
      "Epoch: 949, Loss: 65597096.729\n",
      "Epoch: 950, Loss: 55878555.327\n",
      "Epoch: 951, Loss: 65470354.729\n",
      "Epoch: 952, Loss: 54265761.622\n",
      "Epoch: 953, Loss: 66219968.237\n",
      "Epoch: 954, Loss: 57457534.609\n",
      "Epoch: 955, Loss: 66690595.039\n",
      "Epoch: 956, Loss: 63587308.119\n",
      "Epoch: 957, Loss: 54841765.988\n",
      "Epoch: 958, Loss: 60729836.942\n",
      "Epoch: 959, Loss: 53785086.909\n",
      "Epoch: 960, Loss: 52534913.753\n",
      "Epoch: 961, Loss: 71213511.161\n",
      "Epoch: 962, Loss: 65111601.665\n",
      "Epoch: 963, Loss: 67538284.048\n",
      "Epoch: 964, Loss: 58083443.718\n",
      "Epoch: 965, Loss: 66121301.214\n",
      "Epoch: 966, Loss: 60205886.582\n",
      "Epoch: 967, Loss: 67761292.909\n",
      "Epoch: 968, Loss: 52898168.879\n",
      "Epoch: 969, Loss: 38190179.983\n",
      "Epoch: 970, Loss: 61666616.104\n",
      "Epoch: 971, Loss: 73086745.729\n",
      "Epoch: 972, Loss: 56648521.397\n",
      "Epoch: 973, Loss: 61144448.060\n",
      "Epoch: 974, Loss: 59969275.119\n",
      "Epoch: 975, Loss: 55133121.425\n",
      "Epoch: 976, Loss: 50707668.096\n",
      "Epoch: 977, Loss: 54117759.904\n",
      "Epoch: 978, Loss: 56239238.064\n",
      "Epoch: 979, Loss: 56014468.870\n",
      "Epoch: 980, Loss: 58158251.947\n",
      "Epoch: 981, Loss: 50430192.857\n",
      "Epoch: 982, Loss: 57899558.414\n",
      "Epoch: 983, Loss: 57633002.066\n",
      "Epoch: 984, Loss: 55273296.407\n",
      "Epoch: 985, Loss: 52554996.761\n",
      "Epoch: 986, Loss: 58770173.590\n",
      "Epoch: 987, Loss: 60142564.158\n",
      "Epoch: 988, Loss: 55424226.808\n",
      "Epoch: 989, Loss: 60974540.318\n",
      "Epoch: 990, Loss: 61858202.888\n",
      "Epoch: 991, Loss: 55458438.229\n",
      "Epoch: 992, Loss: 57673373.822\n",
      "Epoch: 993, Loss: 62462385.609\n",
      "Epoch: 994, Loss: 59156325.586\n",
      "Epoch: 995, Loss: 64993068.194\n",
      "Epoch: 996, Loss: 61183442.685\n",
      "Epoch: 997, Loss: 67704266.517\n",
      "Epoch: 998, Loss: 60302906.271\n",
      "Epoch: 999, Loss: 74542391.569\n",
      "Epoch: 1000, Loss: 51179541.692\n",
      "Epoch: 1001, Loss: 63244561.557\n",
      "Epoch: 1002, Loss: 50023500.739\n",
      "Epoch: 1003, Loss: 60997824.339\n",
      "Epoch: 1004, Loss: 52253551.724\n",
      "Epoch: 1005, Loss: 57382092.158\n",
      "Epoch: 1006, Loss: 68598810.807\n",
      "Epoch: 1007, Loss: 61400620.665\n",
      "Epoch: 1008, Loss: 59863473.413\n",
      "Epoch: 1009, Loss: 57210045.300\n",
      "Epoch: 1010, Loss: 72439254.026\n",
      "Epoch: 1011, Loss: 58514718.595\n",
      "Epoch: 1012, Loss: 60955358.331\n",
      "Epoch: 1013, Loss: 63110855.865\n",
      "Epoch: 1014, Loss: 66497438.058\n",
      "Epoch: 1015, Loss: 65775007.266\n",
      "Epoch: 1016, Loss: 61148759.506\n",
      "Epoch: 1017, Loss: 61993594.425\n",
      "Epoch: 1018, Loss: 40964518.734\n",
      "Epoch: 1019, Loss: 80939063.648\n",
      "Epoch: 1020, Loss: 50581017.527\n",
      "Epoch: 1021, Loss: 57171309.280\n",
      "Epoch: 1022, Loss: 50443428.535\n",
      "Epoch: 1023, Loss: 51378672.284\n",
      "Epoch: 1024, Loss: 52731983.095\n",
      "Epoch: 1025, Loss: 66773675.632\n",
      "Epoch: 1026, Loss: 53221623.181\n",
      "Epoch: 1027, Loss: 59066695.894\n",
      "Epoch: 1028, Loss: 58279465.761\n",
      "Epoch: 1029, Loss: 68563214.255\n",
      "Epoch: 1030, Loss: 51853593.704\n",
      "Epoch: 1031, Loss: 67896437.542\n",
      "Epoch: 1032, Loss: 60726219.925\n",
      "Epoch: 1033, Loss: 63371896.295\n",
      "Epoch: 1034, Loss: 68722542.543\n",
      "Epoch: 1035, Loss: 47096762.673\n",
      "Epoch: 1036, Loss: 55005853.097\n",
      "Epoch: 1037, Loss: 64229797.770\n",
      "Epoch: 1038, Loss: 64109577.222\n",
      "Epoch: 1039, Loss: 71849138.337\n",
      "Epoch: 1040, Loss: 49045710.365\n",
      "Epoch: 1041, Loss: 54170303.102\n",
      "Epoch: 1042, Loss: 60281735.749\n",
      "Epoch: 1043, Loss: 61163367.293\n",
      "Epoch: 1044, Loss: 62952003.653\n",
      "Epoch: 1045, Loss: 62082609.151\n",
      "Epoch: 1046, Loss: 58369836.414\n",
      "Epoch: 1047, Loss: 63728867.016\n",
      "Epoch: 1048, Loss: 50491122.986\n",
      "Epoch: 1049, Loss: 58062777.894\n",
      "Epoch: 1050, Loss: 60613074.741\n",
      "Epoch: 1051, Loss: 56145423.773\n",
      "Epoch: 1052, Loss: 71531072.907\n",
      "Epoch: 1053, Loss: 68313067.071\n",
      "Epoch: 1054, Loss: 59126110.625\n",
      "Epoch: 1055, Loss: 66327364.961\n",
      "Epoch: 1056, Loss: 61745496.019\n",
      "Epoch: 1057, Loss: 55362833.690\n",
      "Epoch: 1058, Loss: 47891136.221\n",
      "Epoch: 1059, Loss: 56746204.506\n",
      "Epoch: 1060, Loss: 54490160.186\n",
      "Epoch: 1061, Loss: 64528078.593\n",
      "Epoch: 1062, Loss: 56270873.498\n",
      "Epoch: 1063, Loss: 60621575.526\n",
      "Epoch: 1064, Loss: 65202848.895\n",
      "Epoch: 1065, Loss: 60442922.834\n",
      "Epoch: 1066, Loss: 70013511.901\n",
      "Epoch: 1067, Loss: 60215187.533\n",
      "Epoch: 1068, Loss: 53180001.437\n",
      "Epoch: 1069, Loss: 56877741.089\n",
      "Epoch: 1070, Loss: 57562378.150\n",
      "Epoch: 1071, Loss: 82378164.510\n",
      "Epoch: 1072, Loss: 70213718.336\n",
      "Epoch: 1073, Loss: 61118185.462\n",
      "Epoch: 1074, Loss: 68850282.747\n",
      "Epoch: 1075, Loss: 66833270.824\n",
      "Epoch: 1076, Loss: 61390155.296\n",
      "Epoch: 1077, Loss: 73813437.609\n",
      "Epoch: 1078, Loss: 66811686.059\n",
      "Epoch: 1079, Loss: 42250491.884\n",
      "Epoch: 1080, Loss: 62620881.992\n",
      "Epoch: 1081, Loss: 62138456.557\n",
      "Epoch: 1082, Loss: 54430375.178\n",
      "Epoch: 1083, Loss: 63827170.449\n",
      "Epoch: 1084, Loss: 55849607.420\n",
      "Epoch: 1085, Loss: 57502091.732\n",
      "Epoch: 1086, Loss: 66775633.351\n",
      "Epoch: 1087, Loss: 53945634.055\n",
      "Epoch: 1088, Loss: 54087372.515\n",
      "Epoch: 1089, Loss: 70503710.917\n",
      "Epoch: 1090, Loss: 67474848.552\n",
      "Epoch: 1091, Loss: 55816239.779\n",
      "Epoch: 1092, Loss: 53293159.955\n",
      "Epoch: 1093, Loss: 55370001.317\n",
      "Epoch: 1094, Loss: 55762995.857\n",
      "Epoch: 1095, Loss: 46592992.923\n",
      "Epoch: 1096, Loss: 61353699.848\n",
      "Epoch: 1097, Loss: 60789234.862\n",
      "Epoch: 1098, Loss: 55361184.257\n",
      "Epoch: 1099, Loss: 50328496.160\n",
      "Epoch: 1100, Loss: 59130032.002\n",
      "Epoch: 1101, Loss: 54411419.882\n",
      "Epoch: 1102, Loss: 66893409.705\n",
      "Epoch: 1103, Loss: 59830703.815\n",
      "Epoch: 1104, Loss: 56900044.518\n",
      "Epoch: 1105, Loss: 51108867.985\n",
      "Epoch: 1106, Loss: 52021133.506\n",
      "Epoch: 1107, Loss: 66410326.832\n",
      "Epoch: 1108, Loss: 65824052.186\n",
      "Epoch: 1109, Loss: 57467610.486\n",
      "Epoch: 1110, Loss: 74199531.987\n",
      "Epoch: 1111, Loss: 59295562.762\n",
      "Epoch: 1112, Loss: 55525995.925\n",
      "Epoch: 1113, Loss: 67388904.211\n",
      "Epoch: 1114, Loss: 65729497.487\n",
      "Epoch: 1115, Loss: 65925028.790\n",
      "Epoch: 1116, Loss: 60620504.387\n",
      "Epoch: 1117, Loss: 51936992.347\n",
      "Epoch: 1118, Loss: 63184257.056\n",
      "Epoch: 1119, Loss: 74767721.590\n",
      "Epoch: 1120, Loss: 57290448.867\n",
      "Epoch: 1121, Loss: 62477663.640\n",
      "Epoch: 1122, Loss: 49363479.656\n",
      "Epoch: 1123, Loss: 55862390.832\n",
      "Epoch: 1124, Loss: 49411047.644\n",
      "Epoch: 1125, Loss: 63099723.252\n",
      "Epoch: 1126, Loss: 60450735.845\n",
      "Epoch: 1127, Loss: 57304633.119\n",
      "Epoch: 1128, Loss: 61049787.377\n",
      "Epoch: 1129, Loss: 57711073.939\n",
      "Epoch: 1130, Loss: 61673843.704\n",
      "Epoch: 1131, Loss: 61224620.533\n",
      "Epoch: 1132, Loss: 63772986.485\n",
      "Epoch: 1133, Loss: 62786610.377\n",
      "Epoch: 1134, Loss: 67149825.561\n",
      "Epoch: 1135, Loss: 67316379.310\n",
      "Epoch: 1136, Loss: 70233587.361\n",
      "Epoch: 1137, Loss: 59894704.236\n",
      "Epoch: 1138, Loss: 46467439.775\n",
      "Epoch: 1139, Loss: 62235728.429\n",
      "Epoch: 1140, Loss: 56831484.676\n",
      "Epoch: 1141, Loss: 48254657.968\n",
      "Epoch: 1142, Loss: 64049789.269\n",
      "Epoch: 1143, Loss: 57377880.013\n",
      "Epoch: 1144, Loss: 70333111.085\n",
      "Epoch: 1145, Loss: 64791833.112\n",
      "Epoch: 1146, Loss: 75250061.995\n",
      "Epoch: 1147, Loss: 56892184.933\n",
      "Epoch: 1148, Loss: 58884398.184\n",
      "Epoch: 1149, Loss: 63966718.599\n",
      "Epoch: 1150, Loss: 50754066.885\n",
      "Epoch: 1151, Loss: 56893721.920\n",
      "Epoch: 1152, Loss: 50870565.553\n",
      "Epoch: 1153, Loss: 68020973.526\n",
      "Epoch: 1154, Loss: 57906001.405\n",
      "Epoch: 1155, Loss: 66278617.026\n",
      "Epoch: 1156, Loss: 58731349.233\n",
      "Epoch: 1157, Loss: 67594514.716\n",
      "Epoch: 1158, Loss: 59926219.737\n",
      "Epoch: 1159, Loss: 56597638.745\n",
      "Epoch: 1160, Loss: 58766538.612\n",
      "Epoch: 1161, Loss: 60571580.208\n",
      "Epoch: 1162, Loss: 55669886.995\n",
      "Epoch: 1163, Loss: 60964476.166\n",
      "Epoch: 1164, Loss: 67134243.566\n",
      "Epoch: 1165, Loss: 61973729.729\n",
      "Epoch: 1166, Loss: 64341250.753\n",
      "Epoch: 1167, Loss: 69074240.989\n",
      "Epoch: 1168, Loss: 53169215.510\n",
      "Epoch: 1169, Loss: 54978624.675\n",
      "Epoch: 1170, Loss: 72947637.186\n",
      "Epoch: 1171, Loss: 72509329.431\n",
      "Epoch: 1172, Loss: 53641135.645\n",
      "Epoch: 1173, Loss: 65501221.637\n",
      "Epoch: 1174, Loss: 59097935.848\n",
      "Epoch: 1175, Loss: 55923933.244\n",
      "Epoch: 1176, Loss: 56186735.365\n",
      "Epoch: 1177, Loss: 73910392.508\n",
      "Epoch: 1178, Loss: 56583355.494\n",
      "Epoch: 1179, Loss: 65723802.987\n",
      "Epoch: 1180, Loss: 58656767.438\n",
      "Epoch: 1181, Loss: 53812189.238\n",
      "Epoch: 1182, Loss: 63244482.047\n",
      "Epoch: 1183, Loss: 67731627.475\n",
      "Epoch: 1184, Loss: 61682553.496\n",
      "Epoch: 1185, Loss: 62013123.752\n",
      "Epoch: 1186, Loss: 53024001.529\n",
      "Epoch: 1187, Loss: 57891998.579\n",
      "Epoch: 1188, Loss: 61067564.157\n",
      "Epoch: 1189, Loss: 68724858.468\n",
      "Epoch: 1190, Loss: 54178010.070\n",
      "Epoch: 1191, Loss: 54247330.581\n",
      "Epoch: 1192, Loss: 53481739.286\n",
      "Epoch: 1193, Loss: 62474900.438\n",
      "Epoch: 1194, Loss: 71547076.702\n",
      "Epoch: 1195, Loss: 54428189.828\n",
      "Epoch: 1196, Loss: 62087976.325\n",
      "Epoch: 1197, Loss: 49171158.474\n",
      "Epoch: 1198, Loss: 66156827.118\n",
      "Epoch: 1199, Loss: 59040974.755\n",
      "Epoch: 1200, Loss: 53190111.514\n",
      "Epoch: 1201, Loss: 66547161.554\n",
      "Epoch: 1202, Loss: 59729952.298\n",
      "Epoch: 1203, Loss: 65266496.469\n",
      "Epoch: 1204, Loss: 60025800.536\n",
      "Epoch: 1205, Loss: 58846829.120\n",
      "Epoch: 1206, Loss: 68286956.739\n",
      "Epoch: 1207, Loss: 60101393.622\n",
      "Epoch: 1208, Loss: 62662435.419\n",
      "Epoch: 1209, Loss: 50298951.629\n",
      "Epoch: 1210, Loss: 68086407.876\n",
      "Epoch: 1211, Loss: 54155215.703\n",
      "Epoch: 1212, Loss: 60975474.227\n",
      "Epoch: 1213, Loss: 62029308.055\n",
      "Epoch: 1214, Loss: 52435141.045\n",
      "Epoch: 1215, Loss: 55968705.402\n",
      "Epoch: 1216, Loss: 53658209.371\n",
      "Epoch: 1217, Loss: 51179464.872\n",
      "Epoch: 1218, Loss: 53131828.412\n",
      "Epoch: 1219, Loss: 55203879.144\n",
      "Epoch: 1220, Loss: 68156834.579\n",
      "Epoch: 1221, Loss: 56794199.305\n",
      "Epoch: 1222, Loss: 63004206.322\n",
      "Epoch: 1223, Loss: 58969277.052\n",
      "Epoch: 1224, Loss: 50206970.227\n",
      "Epoch: 1225, Loss: 57407535.766\n",
      "Epoch: 1226, Loss: 57811004.054\n",
      "Epoch: 1227, Loss: 63363665.038\n",
      "Epoch: 1228, Loss: 58179465.727\n",
      "Epoch: 1229, Loss: 63133477.580\n",
      "Epoch: 1230, Loss: 62205347.499\n",
      "Epoch: 1231, Loss: 59055026.174\n",
      "Epoch: 1232, Loss: 48737850.387\n",
      "Epoch: 1233, Loss: 52201155.383\n",
      "Epoch: 1234, Loss: 71205781.027\n",
      "Epoch: 1235, Loss: 60942059.456\n",
      "Epoch: 1236, Loss: 49344339.321\n",
      "Epoch: 1237, Loss: 64019474.448\n",
      "Epoch: 1238, Loss: 69293242.358\n",
      "Epoch: 1239, Loss: 64098446.410\n",
      "Epoch: 1240, Loss: 63672515.850\n",
      "Epoch: 1241, Loss: 60569264.103\n",
      "Epoch: 1242, Loss: 67762052.004\n",
      "Epoch: 1243, Loss: 56225458.875\n",
      "Epoch: 1244, Loss: 66155829.226\n",
      "Epoch: 1245, Loss: 66883152.314\n",
      "Epoch: 1246, Loss: 67706852.168\n",
      "Epoch: 1247, Loss: 47814339.768\n",
      "Epoch: 1248, Loss: 57475786.495\n",
      "Epoch: 1249, Loss: 61806205.226\n",
      "Epoch: 1250, Loss: 60724532.391\n",
      "Epoch: 1251, Loss: 61512257.489\n",
      "Epoch: 1252, Loss: 64812801.538\n",
      "Epoch: 1253, Loss: 54606391.572\n",
      "Epoch: 1254, Loss: 54651843.742\n",
      "Epoch: 1255, Loss: 55535366.616\n",
      "Epoch: 1256, Loss: 58397033.219\n",
      "Epoch: 1257, Loss: 55492036.444\n",
      "Epoch: 1258, Loss: 49438062.785\n",
      "Epoch: 1259, Loss: 67663415.177\n",
      "Epoch: 1260, Loss: 60483721.924\n",
      "Epoch: 1261, Loss: 51035014.924\n",
      "Epoch: 1262, Loss: 56072612.523\n",
      "Epoch: 1263, Loss: 44978520.800\n",
      "Epoch: 1264, Loss: 73769959.822\n",
      "Epoch: 1265, Loss: 63993912.657\n",
      "Epoch: 1266, Loss: 70152530.117\n",
      "Epoch: 1267, Loss: 56302918.904\n",
      "Epoch: 1268, Loss: 60655199.471\n",
      "Epoch: 1269, Loss: 52771303.027\n",
      "Epoch: 1270, Loss: 51496706.096\n",
      "Epoch: 1271, Loss: 58405299.682\n",
      "Epoch: 1272, Loss: 57287297.573\n",
      "Epoch: 1273, Loss: 53085626.316\n",
      "Epoch: 1274, Loss: 74441249.406\n",
      "Epoch: 1275, Loss: 62854567.602\n",
      "Epoch: 1276, Loss: 53297793.184\n",
      "Epoch: 1277, Loss: 67404385.915\n",
      "Epoch: 1278, Loss: 64100577.014\n",
      "Epoch: 1279, Loss: 50005649.915\n",
      "Epoch: 1280, Loss: 58567042.063\n",
      "Epoch: 1281, Loss: 44934902.289\n",
      "Epoch: 1282, Loss: 61649581.152\n",
      "Epoch: 1283, Loss: 61758359.476\n",
      "Epoch: 1284, Loss: 62026993.848\n",
      "Epoch: 1285, Loss: 51396983.254\n",
      "Epoch: 1286, Loss: 58531806.754\n",
      "Epoch: 1287, Loss: 68490811.467\n",
      "Epoch: 1288, Loss: 66465334.189\n",
      "Epoch: 1289, Loss: 65179089.456\n",
      "Epoch: 1290, Loss: 61052600.646\n",
      "Epoch: 1291, Loss: 49932956.941\n",
      "Epoch: 1292, Loss: 56269321.657\n",
      "Epoch: 1293, Loss: 61850251.681\n",
      "Epoch: 1294, Loss: 53242257.015\n",
      "Epoch: 1295, Loss: 70855510.500\n",
      "Epoch: 1296, Loss: 70071677.358\n",
      "Epoch: 1297, Loss: 63351775.197\n",
      "Epoch: 1298, Loss: 62478967.268\n",
      "Epoch: 1299, Loss: 56310486.294\n",
      "Epoch: 1300, Loss: 67880398.978\n",
      "Epoch: 1301, Loss: 60181914.520\n",
      "Epoch: 1302, Loss: 62114202.445\n",
      "Epoch: 1303, Loss: 69581161.087\n",
      "Epoch: 1304, Loss: 55415312.913\n",
      "Epoch: 1305, Loss: 61022012.690\n",
      "Epoch: 1306, Loss: 69580530.302\n",
      "Epoch: 1307, Loss: 63495294.734\n",
      "Epoch: 1308, Loss: 52647423.165\n",
      "Epoch: 1309, Loss: 60868541.466\n",
      "Epoch: 1310, Loss: 52003135.831\n",
      "Epoch: 1311, Loss: 61394815.812\n",
      "Epoch: 1312, Loss: 69634529.641\n",
      "Epoch: 1313, Loss: 64246870.222\n",
      "Epoch: 1314, Loss: 64240016.258\n",
      "Epoch: 1315, Loss: 52210304.533\n",
      "Epoch: 1316, Loss: 51526776.059\n",
      "Epoch: 1317, Loss: 58477597.916\n",
      "Epoch: 1318, Loss: 52028300.937\n",
      "Epoch: 1319, Loss: 61995752.328\n",
      "Epoch: 1320, Loss: 58286740.922\n",
      "Epoch: 1321, Loss: 57637535.296\n",
      "Epoch: 1322, Loss: 65048569.311\n",
      "Epoch: 1323, Loss: 63458166.634\n",
      "Epoch: 1324, Loss: 54783959.396\n",
      "Epoch: 1325, Loss: 66480304.302\n",
      "Epoch: 1326, Loss: 64245500.641\n",
      "Epoch: 1327, Loss: 63805859.766\n",
      "Epoch: 1328, Loss: 67292928.984\n",
      "Epoch: 1329, Loss: 57720318.757\n",
      "Epoch: 1330, Loss: 56364588.933\n",
      "Epoch: 1331, Loss: 60283816.625\n",
      "Epoch: 1332, Loss: 63223679.553\n",
      "Epoch: 1333, Loss: 65856424.619\n",
      "Epoch: 1334, Loss: 59948351.404\n",
      "Epoch: 1335, Loss: 62662008.122\n",
      "Epoch: 1336, Loss: 68252417.592\n",
      "Epoch: 1337, Loss: 56741495.006\n",
      "Epoch: 1338, Loss: 58887099.407\n",
      "Epoch: 1339, Loss: 67589024.251\n",
      "Epoch: 1340, Loss: 55990376.503\n",
      "Epoch: 1341, Loss: 74291288.670\n",
      "Epoch: 1342, Loss: 59557347.273\n",
      "Epoch: 1343, Loss: 49314916.118\n",
      "Epoch: 1344, Loss: 54172882.970\n",
      "Epoch: 1345, Loss: 58096860.384\n",
      "Epoch: 1346, Loss: 67159404.398\n",
      "Epoch: 1347, Loss: 56070959.212\n",
      "Epoch: 1348, Loss: 68333646.937\n",
      "Epoch: 1349, Loss: 50733334.369\n",
      "Epoch: 1350, Loss: 50560023.360\n",
      "Epoch: 1351, Loss: 50357012.953\n",
      "Epoch: 1352, Loss: 59519272.202\n",
      "Epoch: 1353, Loss: 61731522.208\n",
      "Epoch: 1354, Loss: 54118909.463\n",
      "Epoch: 1355, Loss: 66099601.587\n",
      "Epoch: 1356, Loss: 61016463.307\n",
      "Epoch: 1357, Loss: 59469636.501\n",
      "Epoch: 1358, Loss: 57558418.051\n",
      "Epoch: 1359, Loss: 56472027.865\n",
      "Epoch: 1360, Loss: 59584163.479\n",
      "Epoch: 1361, Loss: 52324995.482\n",
      "Epoch: 1362, Loss: 56304421.737\n",
      "Epoch: 1363, Loss: 65718398.002\n",
      "Epoch: 1364, Loss: 62638211.115\n",
      "Epoch: 1365, Loss: 64307426.964\n",
      "Epoch: 1366, Loss: 71900928.350\n",
      "Epoch: 1367, Loss: 56344458.360\n",
      "Epoch: 1368, Loss: 60708431.977\n",
      "Epoch: 1369, Loss: 65647429.176\n",
      "Epoch: 1370, Loss: 65807864.511\n",
      "Epoch: 1371, Loss: 52036342.285\n",
      "Epoch: 1372, Loss: 47292396.242\n",
      "Epoch: 1373, Loss: 67335417.561\n",
      "Epoch: 1374, Loss: 64150294.859\n",
      "Epoch: 1375, Loss: 60354291.549\n",
      "Epoch: 1376, Loss: 60271393.682\n",
      "Epoch: 1377, Loss: 53597145.105\n",
      "Epoch: 1378, Loss: 63867460.350\n",
      "Epoch: 1379, Loss: 46223848.988\n",
      "Epoch: 1380, Loss: 57746121.230\n",
      "Epoch: 1381, Loss: 68953105.196\n",
      "Epoch: 1382, Loss: 55607880.752\n",
      "Epoch: 1383, Loss: 71088381.260\n",
      "Epoch: 1384, Loss: 60578032.633\n",
      "Epoch: 1385, Loss: 53900227.078\n",
      "Epoch: 1386, Loss: 64657276.504\n",
      "Epoch: 1387, Loss: 61541509.371\n",
      "Epoch: 1388, Loss: 62563398.453\n",
      "Epoch: 1389, Loss: 57107041.178\n",
      "Epoch: 1390, Loss: 59901272.078\n",
      "Epoch: 1391, Loss: 62717612.394\n",
      "Epoch: 1392, Loss: 56977306.526\n",
      "Epoch: 1393, Loss: 60509508.981\n",
      "Epoch: 1394, Loss: 53505310.348\n",
      "Epoch: 1395, Loss: 48196626.767\n",
      "Epoch: 1396, Loss: 65659307.188\n",
      "Epoch: 1397, Loss: 55881899.977\n",
      "Epoch: 1398, Loss: 68985469.833\n",
      "Epoch: 1399, Loss: 56563241.560\n",
      "Epoch: 1400, Loss: 51459620.561\n",
      "Epoch: 1401, Loss: 50608789.895\n",
      "Epoch: 1402, Loss: 67342253.273\n",
      "Epoch: 1403, Loss: 63286858.203\n",
      "Epoch: 1404, Loss: 55164699.085\n",
      "Epoch: 1405, Loss: 52704972.940\n",
      "Epoch: 1406, Loss: 71130881.577\n",
      "Epoch: 1407, Loss: 60995982.577\n",
      "Epoch: 1408, Loss: 65080396.852\n",
      "Epoch: 1409, Loss: 55071858.979\n",
      "Epoch: 1410, Loss: 72215112.976\n",
      "Epoch: 1411, Loss: 48327318.512\n",
      "Epoch: 1412, Loss: 60283633.146\n",
      "Epoch: 1413, Loss: 55401892.798\n",
      "Epoch: 1414, Loss: 47182499.793\n",
      "Epoch: 1415, Loss: 65020958.032\n",
      "Epoch: 1416, Loss: 60028029.895\n",
      "Epoch: 1417, Loss: 65890804.908\n",
      "Epoch: 1418, Loss: 66198066.013\n",
      "Epoch: 1419, Loss: 63514220.962\n",
      "Epoch: 1420, Loss: 61876822.841\n",
      "Epoch: 1421, Loss: 66529647.461\n",
      "Epoch: 1422, Loss: 64386278.537\n",
      "Epoch: 1423, Loss: 57744787.881\n",
      "Epoch: 1424, Loss: 45482791.205\n",
      "Epoch: 1425, Loss: 69467052.728\n",
      "Epoch: 1426, Loss: 65238339.506\n",
      "Epoch: 1427, Loss: 58778976.559\n",
      "Epoch: 1428, Loss: 58312210.694\n",
      "Epoch: 1429, Loss: 69280045.688\n",
      "Epoch: 1430, Loss: 56951788.246\n",
      "Epoch: 1431, Loss: 65767433.698\n",
      "Epoch: 1432, Loss: 61191633.096\n",
      "Epoch: 1433, Loss: 56831110.657\n",
      "Epoch: 1434, Loss: 59829192.689\n",
      "Epoch: 1435, Loss: 54870449.503\n",
      "Epoch: 1436, Loss: 63284342.266\n",
      "Epoch: 1437, Loss: 59792739.581\n",
      "Epoch: 1438, Loss: 48463816.020\n",
      "Epoch: 1439, Loss: 54557269.933\n",
      "Epoch: 1440, Loss: 61448852.304\n",
      "Epoch: 1441, Loss: 59362543.969\n",
      "Epoch: 1442, Loss: 59859611.320\n",
      "Epoch: 1443, Loss: 67469793.896\n",
      "Epoch: 1444, Loss: 52200713.874\n",
      "Epoch: 1445, Loss: 70745438.770\n",
      "Epoch: 1446, Loss: 59688009.589\n",
      "Epoch: 1447, Loss: 50895243.856\n",
      "Epoch: 1448, Loss: 57333935.917\n",
      "Epoch: 1449, Loss: 49653197.964\n",
      "Epoch: 1450, Loss: 59670779.540\n",
      "Epoch: 1451, Loss: 55045493.472\n",
      "Epoch: 1452, Loss: 70416985.391\n",
      "Epoch: 1453, Loss: 75461994.099\n",
      "Epoch: 1454, Loss: 46852933.806\n",
      "Epoch: 1455, Loss: 64118191.907\n",
      "Epoch: 1456, Loss: 57539024.058\n",
      "Epoch: 1457, Loss: 56589136.786\n",
      "Epoch: 1458, Loss: 69580825.066\n",
      "Epoch: 1459, Loss: 61151936.923\n",
      "Epoch: 1460, Loss: 60136244.548\n",
      "Epoch: 1461, Loss: 59315930.140\n",
      "Epoch: 1462, Loss: 55106154.053\n",
      "Epoch: 1463, Loss: 70095067.857\n",
      "Epoch: 1464, Loss: 69818389.476\n",
      "Epoch: 1465, Loss: 46054629.127\n",
      "Epoch: 1466, Loss: 58611818.966\n",
      "Epoch: 1467, Loss: 46621091.803\n",
      "Epoch: 1468, Loss: 52949599.158\n",
      "Epoch: 1469, Loss: 65126641.324\n",
      "Epoch: 1470, Loss: 59073819.014\n",
      "Epoch: 1471, Loss: 49867590.889\n",
      "Epoch: 1472, Loss: 68814987.776\n",
      "Epoch: 1473, Loss: 65129642.691\n",
      "Epoch: 1474, Loss: 51587320.651\n",
      "Epoch: 1475, Loss: 52215479.192\n",
      "Epoch: 1476, Loss: 56383976.012\n",
      "Epoch: 1477, Loss: 59698641.596\n",
      "Epoch: 1478, Loss: 55618738.829\n",
      "Epoch: 1479, Loss: 67855451.284\n",
      "Epoch: 1480, Loss: 60156616.157\n",
      "Epoch: 1481, Loss: 61221273.252\n",
      "Epoch: 1482, Loss: 60023516.414\n",
      "Epoch: 1483, Loss: 57199264.668\n",
      "Epoch: 1484, Loss: 54623232.237\n",
      "Epoch: 1485, Loss: 59992769.949\n",
      "Epoch: 1486, Loss: 60332946.723\n",
      "Epoch: 1487, Loss: 70686982.952\n",
      "Epoch: 1488, Loss: 49969697.597\n",
      "Epoch: 1489, Loss: 46967380.220\n",
      "Epoch: 1490, Loss: 67477862.376\n",
      "Epoch: 1491, Loss: 59647866.497\n",
      "Epoch: 1492, Loss: 52731900.979\n",
      "Epoch: 1493, Loss: 65139856.380\n",
      "Epoch: 1494, Loss: 65565106.503\n",
      "Epoch: 1495, Loss: 64660304.717\n",
      "Epoch: 1496, Loss: 51516204.721\n",
      "Epoch: 1497, Loss: 52994241.944\n",
      "Epoch: 1498, Loss: 75252506.309\n",
      "Epoch: 1499, Loss: 59383452.467\n",
      "Epoch: 1500, Loss: 67404720.824\n",
      "Epoch: 1501, Loss: 61586536.154\n",
      "Epoch: 1502, Loss: 56207727.096\n",
      "Epoch: 1503, Loss: 41581492.975\n",
      "Epoch: 1504, Loss: 57838593.219\n",
      "Epoch: 1505, Loss: 45613006.007\n",
      "Epoch: 1506, Loss: 61048431.804\n",
      "Epoch: 1507, Loss: 67889462.100\n",
      "Epoch: 1508, Loss: 62188458.953\n",
      "Epoch: 1509, Loss: 55206173.779\n",
      "Epoch: 1510, Loss: 52593644.048\n",
      "Epoch: 1511, Loss: 66712155.504\n",
      "Epoch: 1512, Loss: 64087401.135\n",
      "Epoch: 1513, Loss: 64825293.632\n",
      "Epoch: 1514, Loss: 68666268.429\n",
      "Epoch: 1515, Loss: 69903451.001\n",
      "Epoch: 1516, Loss: 57190475.920\n",
      "Epoch: 1517, Loss: 61747443.862\n",
      "Epoch: 1518, Loss: 58260542.789\n",
      "Epoch: 1519, Loss: 67440893.714\n",
      "Epoch: 1520, Loss: 61833247.822\n",
      "Epoch: 1521, Loss: 72151988.626\n",
      "Epoch: 1522, Loss: 59850686.046\n",
      "Epoch: 1523, Loss: 65876519.616\n",
      "Epoch: 1524, Loss: 63957937.369\n",
      "Epoch: 1525, Loss: 65152580.822\n",
      "Epoch: 1526, Loss: 58640017.489\n",
      "Epoch: 1527, Loss: 58359957.333\n",
      "Epoch: 1528, Loss: 73602001.797\n",
      "Epoch: 1529, Loss: 61203817.724\n",
      "Epoch: 1530, Loss: 51085348.619\n",
      "Epoch: 1531, Loss: 61047656.119\n",
      "Epoch: 1532, Loss: 53787779.856\n",
      "Epoch: 1533, Loss: 49051911.519\n",
      "Epoch: 1534, Loss: 61784244.967\n",
      "Epoch: 1535, Loss: 54203163.916\n",
      "Epoch: 1536, Loss: 58197012.717\n",
      "Epoch: 1537, Loss: 66883193.149\n",
      "Epoch: 1538, Loss: 55203904.970\n",
      "Epoch: 1539, Loss: 65088305.263\n",
      "Epoch: 1540, Loss: 64053316.964\n",
      "Epoch: 1541, Loss: 59877600.402\n",
      "Epoch: 1542, Loss: 55836136.301\n",
      "Epoch: 1543, Loss: 55065841.962\n",
      "Epoch: 1544, Loss: 69697641.632\n",
      "Epoch: 1545, Loss: 63813315.922\n",
      "Epoch: 1546, Loss: 57931580.875\n",
      "Epoch: 1547, Loss: 60838259.459\n",
      "Epoch: 1548, Loss: 59651597.712\n",
      "Epoch: 1549, Loss: 53866660.945\n",
      "Epoch: 1550, Loss: 52291671.955\n",
      "Epoch: 1551, Loss: 57074969.235\n",
      "Epoch: 1552, Loss: 57172281.171\n",
      "Epoch: 1553, Loss: 53157727.659\n",
      "Epoch: 1554, Loss: 58723492.822\n",
      "Epoch: 1555, Loss: 53313464.620\n",
      "Epoch: 1556, Loss: 70026697.443\n",
      "Epoch: 1557, Loss: 55084498.907\n",
      "Epoch: 1558, Loss: 61656138.134\n",
      "Epoch: 1559, Loss: 69636135.205\n",
      "Epoch: 1560, Loss: 56302337.457\n",
      "Epoch: 1561, Loss: 53952622.384\n",
      "Epoch: 1562, Loss: 48020319.140\n",
      "Epoch: 1563, Loss: 48837413.216\n",
      "Epoch: 1564, Loss: 58545692.255\n",
      "Epoch: 1565, Loss: 54460136.041\n",
      "Epoch: 1566, Loss: 47462943.751\n",
      "Epoch: 1567, Loss: 63467401.683\n",
      "Epoch: 1568, Loss: 60132253.361\n",
      "Epoch: 1569, Loss: 59661801.349\n",
      "Epoch: 1570, Loss: 57783285.424\n",
      "Epoch: 1571, Loss: 65178135.523\n",
      "Epoch: 1572, Loss: 54734182.805\n",
      "Epoch: 1573, Loss: 62700195.009\n",
      "Epoch: 1574, Loss: 63033878.316\n",
      "Epoch: 1575, Loss: 66914623.845\n",
      "Epoch: 1576, Loss: 58005932.989\n",
      "Epoch: 1577, Loss: 64179036.128\n",
      "Epoch: 1578, Loss: 62497615.169\n",
      "Epoch: 1579, Loss: 77382799.775\n",
      "Epoch: 1580, Loss: 59744564.431\n",
      "Epoch: 1581, Loss: 58806576.455\n",
      "Epoch: 1582, Loss: 59498771.493\n",
      "Epoch: 1583, Loss: 59112713.775\n",
      "Epoch: 1584, Loss: 65035018.282\n",
      "Epoch: 1585, Loss: 59236150.196\n",
      "Epoch: 1586, Loss: 55139366.628\n",
      "Epoch: 1587, Loss: 63621052.743\n",
      "Epoch: 1588, Loss: 74351315.404\n",
      "Epoch: 1589, Loss: 62466855.747\n",
      "Epoch: 1590, Loss: 53558148.462\n",
      "Epoch: 1591, Loss: 44908245.116\n",
      "Epoch: 1592, Loss: 61183675.223\n",
      "Epoch: 1593, Loss: 76177663.471\n",
      "Epoch: 1594, Loss: 60497040.510\n",
      "Epoch: 1595, Loss: 54908225.983\n",
      "Epoch: 1596, Loss: 62082530.644\n",
      "Epoch: 1597, Loss: 53063394.637\n",
      "Epoch: 1598, Loss: 67128417.097\n",
      "Epoch: 1599, Loss: 60957610.414\n",
      "Epoch: 1600, Loss: 59631280.639\n",
      "Epoch: 1601, Loss: 51403070.998\n",
      "Epoch: 1602, Loss: 62623539.434\n",
      "Epoch: 1603, Loss: 56911296.121\n",
      "Epoch: 1604, Loss: 60345879.282\n",
      "Epoch: 1605, Loss: 57558371.853\n",
      "Epoch: 1606, Loss: 66608193.176\n",
      "Epoch: 1607, Loss: 60543953.997\n",
      "Epoch: 1608, Loss: 52675185.178\n",
      "Epoch: 1609, Loss: 56876805.759\n",
      "Epoch: 1610, Loss: 61755930.656\n",
      "Epoch: 1611, Loss: 49279299.197\n",
      "Epoch: 1612, Loss: 52703187.031\n",
      "Epoch: 1613, Loss: 58220816.043\n",
      "Epoch: 1614, Loss: 70369391.974\n",
      "Epoch: 1615, Loss: 62408984.705\n",
      "Epoch: 1616, Loss: 62046801.986\n",
      "Epoch: 1617, Loss: 50267147.243\n",
      "Epoch: 1618, Loss: 51940401.094\n",
      "Epoch: 1619, Loss: 52044017.098\n",
      "Epoch: 1620, Loss: 55514098.573\n",
      "Epoch: 1621, Loss: 60456526.061\n",
      "Epoch: 1622, Loss: 45960499.901\n",
      "Epoch: 1623, Loss: 57604894.565\n",
      "Epoch: 1624, Loss: 54907277.427\n",
      "Epoch: 1625, Loss: 60954165.953\n",
      "Epoch: 1626, Loss: 66655962.566\n",
      "Epoch: 1627, Loss: 68995883.247\n",
      "Epoch: 1628, Loss: 49509834.914\n",
      "Epoch: 1629, Loss: 50025939.309\n",
      "Epoch: 1630, Loss: 57047745.737\n",
      "Epoch: 1631, Loss: 52767921.555\n",
      "Epoch: 1632, Loss: 56904574.946\n",
      "Epoch: 1633, Loss: 52232867.677\n",
      "Epoch: 1634, Loss: 55669684.579\n",
      "Epoch: 1635, Loss: 51969265.693\n",
      "Epoch: 1636, Loss: 53302918.983\n",
      "Epoch: 1637, Loss: 58587818.925\n",
      "Epoch: 1638, Loss: 55827866.056\n",
      "Epoch: 1639, Loss: 52204465.473\n",
      "Epoch: 1640, Loss: 52053197.105\n",
      "Epoch: 1641, Loss: 51440651.294\n",
      "Epoch: 1642, Loss: 56027590.019\n",
      "Epoch: 1643, Loss: 49119969.863\n",
      "Epoch: 1644, Loss: 80718848.873\n",
      "Epoch: 1645, Loss: 60960335.084\n",
      "Epoch: 1646, Loss: 67332140.945\n",
      "Epoch: 1647, Loss: 65824155.888\n",
      "Epoch: 1648, Loss: 52705642.663\n",
      "Epoch: 1649, Loss: 53386118.795\n",
      "Epoch: 1650, Loss: 55444414.417\n",
      "Epoch: 1651, Loss: 58480298.300\n",
      "Epoch: 1652, Loss: 62348881.092\n",
      "Epoch: 1653, Loss: 60369014.135\n",
      "Epoch: 1654, Loss: 58941546.651\n",
      "Epoch: 1655, Loss: 58945499.140\n",
      "Epoch: 1656, Loss: 65472661.034\n",
      "Epoch: 1657, Loss: 65699777.377\n",
      "Epoch: 1658, Loss: 57587022.129\n",
      "Epoch: 1659, Loss: 54871618.458\n",
      "Epoch: 1660, Loss: 57197516.036\n",
      "Epoch: 1661, Loss: 53722880.451\n",
      "Epoch: 1662, Loss: 57307758.893\n",
      "Epoch: 1663, Loss: 53900886.545\n",
      "Epoch: 1664, Loss: 72718521.241\n",
      "Epoch: 1665, Loss: 48610081.336\n",
      "Epoch: 1666, Loss: 65787430.315\n",
      "Epoch: 1667, Loss: 68703394.386\n",
      "Epoch: 1668, Loss: 61082891.534\n",
      "Epoch: 1669, Loss: 60486948.077\n",
      "Epoch: 1670, Loss: 64363760.984\n",
      "Epoch: 1671, Loss: 60115438.607\n",
      "Epoch: 1672, Loss: 56166953.409\n",
      "Epoch: 1673, Loss: 53728740.232\n",
      "Epoch: 1674, Loss: 51349827.713\n",
      "Epoch: 1675, Loss: 63873301.931\n",
      "Epoch: 1676, Loss: 60580324.038\n",
      "Epoch: 1677, Loss: 60794367.586\n",
      "Epoch: 1678, Loss: 66300981.743\n",
      "Epoch: 1679, Loss: 64028621.214\n",
      "Epoch: 1680, Loss: 58544470.595\n",
      "Epoch: 1681, Loss: 63348265.097\n",
      "Epoch: 1682, Loss: 63027252.081\n",
      "Epoch: 1683, Loss: 67828249.460\n",
      "Epoch: 1684, Loss: 76087254.014\n",
      "Epoch: 1685, Loss: 61785471.918\n",
      "Epoch: 1686, Loss: 64485763.885\n",
      "Epoch: 1687, Loss: 47489985.576\n",
      "Epoch: 1688, Loss: 55390950.286\n",
      "Epoch: 1689, Loss: 50938730.530\n",
      "Epoch: 1690, Loss: 65201819.381\n",
      "Epoch: 1691, Loss: 69223332.355\n",
      "Epoch: 1692, Loss: 67198833.902\n",
      "Epoch: 1693, Loss: 63812450.439\n",
      "Epoch: 1694, Loss: 63406607.984\n",
      "Epoch: 1695, Loss: 51251060.320\n",
      "Epoch: 1696, Loss: 63133130.167\n",
      "Epoch: 1697, Loss: 62075142.453\n",
      "Epoch: 1698, Loss: 65627825.178\n",
      "Epoch: 1699, Loss: 67545428.057\n",
      "Epoch: 1700, Loss: 70079261.641\n",
      "Epoch: 1701, Loss: 55278209.122\n",
      "Epoch: 1702, Loss: 69108641.711\n",
      "Epoch: 1703, Loss: 70521506.152\n",
      "Epoch: 1704, Loss: 56086010.463\n",
      "Epoch: 1705, Loss: 63024312.314\n",
      "Epoch: 1706, Loss: 61006712.184\n",
      "Epoch: 1707, Loss: 66041038.612\n",
      "Epoch: 1708, Loss: 65654251.207\n",
      "Epoch: 1709, Loss: 69815764.554\n",
      "Epoch: 1710, Loss: 69775878.383\n",
      "Epoch: 1711, Loss: 67127721.651\n",
      "Epoch: 1712, Loss: 64772388.369\n",
      "Epoch: 1713, Loss: 60129520.092\n",
      "Epoch: 1714, Loss: 72767700.058\n",
      "Epoch: 1715, Loss: 61665486.177\n",
      "Epoch: 1716, Loss: 57035594.764\n",
      "Epoch: 1717, Loss: 52962456.509\n",
      "Epoch: 1718, Loss: 52399518.876\n",
      "Epoch: 1719, Loss: 58107001.737\n",
      "Epoch: 1720, Loss: 63440952.236\n",
      "Epoch: 1721, Loss: 64481256.254\n",
      "Epoch: 1722, Loss: 55594579.616\n",
      "Epoch: 1723, Loss: 57481697.639\n",
      "Epoch: 1724, Loss: 60378391.892\n",
      "Epoch: 1725, Loss: 61494626.853\n",
      "Epoch: 1726, Loss: 63202729.560\n",
      "Epoch: 1727, Loss: 67382328.373\n",
      "Epoch: 1728, Loss: 46608857.755\n",
      "Epoch: 1729, Loss: 56863220.651\n",
      "Epoch: 1730, Loss: 58682331.173\n",
      "Epoch: 1731, Loss: 65885771.616\n",
      "Epoch: 1732, Loss: 51270500.182\n",
      "Epoch: 1733, Loss: 59531409.931\n",
      "Epoch: 1734, Loss: 58657830.316\n",
      "Epoch: 1735, Loss: 57820182.440\n",
      "Epoch: 1736, Loss: 64608019.459\n",
      "Epoch: 1737, Loss: 53735574.537\n",
      "Epoch: 1738, Loss: 73495713.918\n",
      "Epoch: 1739, Loss: 78941634.156\n",
      "Epoch: 1740, Loss: 59518542.727\n",
      "Epoch: 1741, Loss: 64604293.603\n",
      "Epoch: 1742, Loss: 52200702.461\n",
      "Epoch: 1743, Loss: 59938587.552\n",
      "Epoch: 1744, Loss: 64347210.198\n",
      "Epoch: 1745, Loss: 61191030.826\n",
      "Epoch: 1746, Loss: 53502030.889\n",
      "Epoch: 1747, Loss: 56563546.825\n",
      "Epoch: 1748, Loss: 58328535.593\n",
      "Epoch: 1749, Loss: 65082822.754\n",
      "Epoch: 1750, Loss: 60722010.004\n",
      "Epoch: 1751, Loss: 62953398.174\n",
      "Epoch: 1752, Loss: 59680755.157\n",
      "Epoch: 1753, Loss: 53422212.381\n",
      "Epoch: 1754, Loss: 64207957.733\n",
      "Epoch: 1755, Loss: 64274566.834\n",
      "Epoch: 1756, Loss: 58772673.521\n",
      "Epoch: 1757, Loss: 61682887.151\n",
      "Epoch: 1758, Loss: 70809914.141\n",
      "Epoch: 1759, Loss: 53026671.576\n",
      "Epoch: 1760, Loss: 69965158.507\n",
      "Epoch: 1761, Loss: 62376986.480\n",
      "Epoch: 1762, Loss: 73682338.220\n",
      "Epoch: 1763, Loss: 62046923.196\n",
      "Epoch: 1764, Loss: 56449530.047\n",
      "Epoch: 1765, Loss: 54054927.616\n",
      "Epoch: 1766, Loss: 68339774.021\n",
      "Epoch: 1767, Loss: 67183856.749\n",
      "Epoch: 1768, Loss: 67040796.938\n",
      "Epoch: 1769, Loss: 72160246.221\n",
      "Epoch: 1770, Loss: 55178248.474\n",
      "Epoch: 1771, Loss: 75407461.930\n",
      "Epoch: 1772, Loss: 64429344.991\n",
      "Epoch: 1773, Loss: 60094034.253\n",
      "Epoch: 1774, Loss: 63926608.834\n",
      "Epoch: 1775, Loss: 56801980.223\n",
      "Epoch: 1776, Loss: 60073886.071\n",
      "Epoch: 1777, Loss: 57779823.376\n",
      "Epoch: 1778, Loss: 57928675.822\n",
      "Epoch: 1779, Loss: 65083843.427\n",
      "Epoch: 1780, Loss: 64097079.523\n",
      "Epoch: 1781, Loss: 59699233.097\n",
      "Epoch: 1782, Loss: 51919180.955\n",
      "Epoch: 1783, Loss: 56155708.820\n",
      "Epoch: 1784, Loss: 51703706.226\n",
      "Epoch: 1785, Loss: 55157422.886\n",
      "Epoch: 1786, Loss: 50580553.687\n",
      "Epoch: 1787, Loss: 69696277.133\n",
      "Epoch: 1788, Loss: 62568999.506\n",
      "Epoch: 1789, Loss: 70986484.457\n",
      "Epoch: 1790, Loss: 50519558.051\n",
      "Epoch: 1791, Loss: 69540154.559\n",
      "Epoch: 1792, Loss: 63470846.213\n",
      "Epoch: 1793, Loss: 61088442.114\n",
      "Epoch: 1794, Loss: 66647865.260\n",
      "Epoch: 1795, Loss: 67710999.815\n",
      "Epoch: 1796, Loss: 70608134.596\n",
      "Epoch: 1797, Loss: 67877549.401\n",
      "Epoch: 1798, Loss: 70598919.740\n",
      "Epoch: 1799, Loss: 61411251.669\n",
      "Epoch: 1800, Loss: 59539229.462\n",
      "Epoch: 1801, Loss: 56821961.308\n",
      "Epoch: 1802, Loss: 51033032.147\n",
      "Epoch: 1803, Loss: 57009306.561\n",
      "Epoch: 1804, Loss: 60680050.510\n",
      "Epoch: 1805, Loss: 57069034.617\n",
      "Epoch: 1806, Loss: 59647355.489\n",
      "Epoch: 1807, Loss: 66708535.807\n",
      "Epoch: 1808, Loss: 60425369.719\n",
      "Epoch: 1809, Loss: 63230620.148\n",
      "Epoch: 1810, Loss: 58108981.788\n",
      "Epoch: 1811, Loss: 63189334.245\n",
      "Epoch: 1812, Loss: 61780866.408\n",
      "Epoch: 1813, Loss: 63676344.852\n",
      "Epoch: 1814, Loss: 56304424.648\n",
      "Epoch: 1815, Loss: 59893470.490\n",
      "Epoch: 1816, Loss: 59334442.505\n",
      "Epoch: 1817, Loss: 65776258.230\n",
      "Epoch: 1818, Loss: 50380267.101\n",
      "Epoch: 1819, Loss: 59607865.184\n",
      "Epoch: 1820, Loss: 59977180.804\n",
      "Epoch: 1821, Loss: 60530785.980\n",
      "Epoch: 1822, Loss: 46957213.828\n",
      "Epoch: 1823, Loss: 58749000.156\n",
      "Epoch: 1824, Loss: 55070487.724\n",
      "Epoch: 1825, Loss: 60696550.953\n",
      "Epoch: 1826, Loss: 55539471.732\n",
      "Epoch: 1827, Loss: 61245689.175\n",
      "Epoch: 1828, Loss: 57235867.289\n",
      "Epoch: 1829, Loss: 54173858.093\n",
      "Epoch: 1830, Loss: 60910834.087\n",
      "Epoch: 1831, Loss: 66293251.625\n",
      "Epoch: 1832, Loss: 57542286.083\n",
      "Epoch: 1833, Loss: 62573575.968\n",
      "Epoch: 1834, Loss: 54773202.824\n",
      "Epoch: 1835, Loss: 58201380.135\n",
      "Epoch: 1836, Loss: 68494946.530\n",
      "Epoch: 1837, Loss: 56711407.900\n",
      "Epoch: 1838, Loss: 53750690.187\n",
      "Epoch: 1839, Loss: 62316283.855\n",
      "Epoch: 1840, Loss: 51081346.344\n",
      "Epoch: 1841, Loss: 62276440.913\n",
      "Epoch: 1842, Loss: 70275410.724\n",
      "Epoch: 1843, Loss: 65574991.926\n",
      "Epoch: 1844, Loss: 58314831.954\n",
      "Epoch: 1845, Loss: 56083017.158\n",
      "Epoch: 1846, Loss: 58989275.912\n",
      "Epoch: 1847, Loss: 66775166.280\n",
      "Epoch: 1848, Loss: 71931650.729\n",
      "Epoch: 1849, Loss: 68689515.726\n",
      "Epoch: 1850, Loss: 71026304.298\n",
      "Epoch: 1851, Loss: 70642195.992\n",
      "Epoch: 1852, Loss: 62988442.263\n",
      "Epoch: 1853, Loss: 52223333.890\n",
      "Epoch: 1854, Loss: 74037719.842\n",
      "Epoch: 1855, Loss: 49628691.197\n",
      "Epoch: 1856, Loss: 57048190.266\n",
      "Epoch: 1857, Loss: 72629945.759\n",
      "Epoch: 1858, Loss: 66444533.189\n",
      "Epoch: 1859, Loss: 68038864.622\n",
      "Epoch: 1860, Loss: 64620135.421\n",
      "Epoch: 1861, Loss: 64794127.654\n",
      "Epoch: 1862, Loss: 65659174.850\n",
      "Epoch: 1863, Loss: 66617761.232\n",
      "Epoch: 1864, Loss: 57326977.120\n",
      "Epoch: 1865, Loss: 75503259.170\n",
      "Epoch: 1866, Loss: 54508058.663\n",
      "Epoch: 1867, Loss: 64756511.288\n",
      "Epoch: 1868, Loss: 59307793.104\n",
      "Epoch: 1869, Loss: 68642294.748\n",
      "Epoch: 1870, Loss: 73976564.403\n",
      "Epoch: 1871, Loss: 76911260.621\n",
      "Epoch: 1872, Loss: 66452931.651\n",
      "Epoch: 1873, Loss: 60615116.879\n",
      "Epoch: 1874, Loss: 66762055.617\n",
      "Epoch: 1875, Loss: 56394572.714\n",
      "Epoch: 1876, Loss: 50586498.118\n",
      "Epoch: 1877, Loss: 70062132.435\n",
      "Epoch: 1878, Loss: 56525049.706\n",
      "Epoch: 1879, Loss: 57739632.255\n",
      "Epoch: 1880, Loss: 70790230.451\n",
      "Epoch: 1881, Loss: 36837440.689\n",
      "Epoch: 1882, Loss: 51161499.264\n",
      "Epoch: 1883, Loss: 62538317.331\n",
      "Epoch: 1884, Loss: 46273919.129\n",
      "Epoch: 1885, Loss: 69070641.810\n",
      "Epoch: 1886, Loss: 63252131.828\n",
      "Epoch: 1887, Loss: 53830866.216\n",
      "Epoch: 1888, Loss: 60191312.061\n",
      "Epoch: 1889, Loss: 54324500.372\n",
      "Epoch: 1890, Loss: 64396360.908\n",
      "Epoch: 1891, Loss: 62603472.980\n",
      "Epoch: 1892, Loss: 57722577.189\n",
      "Epoch: 1893, Loss: 53605982.801\n",
      "Epoch: 1894, Loss: 66136313.867\n",
      "Epoch: 1895, Loss: 60618847.983\n",
      "Epoch: 1896, Loss: 65857220.059\n",
      "Epoch: 1897, Loss: 59436086.501\n",
      "Epoch: 1898, Loss: 55248196.038\n",
      "Epoch: 1899, Loss: 64919972.508\n",
      "Epoch: 1900, Loss: 71518098.371\n",
      "Epoch: 1901, Loss: 69740420.909\n",
      "Epoch: 1902, Loss: 64854780.265\n",
      "Epoch: 1903, Loss: 60366739.511\n",
      "Epoch: 1904, Loss: 55216608.269\n",
      "Epoch: 1905, Loss: 54299281.583\n",
      "Epoch: 1906, Loss: 60629254.638\n",
      "Epoch: 1907, Loss: 64290931.402\n",
      "Epoch: 1908, Loss: 64629631.136\n",
      "Epoch: 1909, Loss: 65154965.624\n",
      "Epoch: 1910, Loss: 62717936.844\n",
      "Epoch: 1911, Loss: 58195568.192\n",
      "Epoch: 1912, Loss: 61136612.941\n",
      "Epoch: 1913, Loss: 50410663.581\n",
      "Epoch: 1914, Loss: 56825598.575\n",
      "Epoch: 1915, Loss: 51165613.591\n",
      "Epoch: 1916, Loss: 61318943.945\n",
      "Epoch: 1917, Loss: 54589183.316\n",
      "Epoch: 1918, Loss: 69872078.760\n",
      "Epoch: 1919, Loss: 60374248.786\n",
      "Epoch: 1920, Loss: 68191219.174\n",
      "Epoch: 1921, Loss: 51945766.000\n",
      "Epoch: 1922, Loss: 50755246.853\n",
      "Epoch: 1923, Loss: 61739155.468\n",
      "Epoch: 1924, Loss: 55157246.928\n",
      "Epoch: 1925, Loss: 64000530.512\n",
      "Epoch: 1926, Loss: 43004754.748\n",
      "Epoch: 1927, Loss: 45762560.760\n",
      "Epoch: 1928, Loss: 54304598.060\n",
      "Epoch: 1929, Loss: 60324154.114\n",
      "Epoch: 1930, Loss: 64102575.194\n",
      "Epoch: 1931, Loss: 73212882.114\n",
      "Epoch: 1932, Loss: 62662637.351\n",
      "Epoch: 1933, Loss: 57956653.471\n",
      "Epoch: 1934, Loss: 56063756.747\n",
      "Epoch: 1935, Loss: 61501209.763\n",
      "Epoch: 1936, Loss: 60125464.826\n",
      "Epoch: 1937, Loss: 69974151.473\n",
      "Epoch: 1938, Loss: 53311001.404\n",
      "Epoch: 1939, Loss: 57558971.379\n",
      "Epoch: 1940, Loss: 51999190.247\n",
      "Epoch: 1941, Loss: 60956463.911\n",
      "Epoch: 1942, Loss: 61742269.712\n",
      "Epoch: 1943, Loss: 58374481.928\n",
      "Epoch: 1944, Loss: 54849055.904\n",
      "Epoch: 1945, Loss: 58021768.440\n",
      "Epoch: 1946, Loss: 64157654.274\n",
      "Epoch: 1947, Loss: 60434924.955\n",
      "Epoch: 1948, Loss: 64291469.463\n",
      "Epoch: 1949, Loss: 60695556.121\n",
      "Epoch: 1950, Loss: 73550945.307\n",
      "Epoch: 1951, Loss: 60514286.243\n",
      "Epoch: 1952, Loss: 69552552.027\n",
      "Epoch: 1953, Loss: 50079638.955\n",
      "Epoch: 1954, Loss: 55042009.551\n",
      "Epoch: 1955, Loss: 61734926.475\n",
      "Epoch: 1956, Loss: 67771394.333\n",
      "Epoch: 1957, Loss: 65512892.594\n",
      "Epoch: 1958, Loss: 51293770.568\n",
      "Epoch: 1959, Loss: 69902548.940\n",
      "Epoch: 1960, Loss: 58619404.867\n",
      "Epoch: 1961, Loss: 64604232.705\n",
      "Epoch: 1962, Loss: 59963310.507\n",
      "Epoch: 1963, Loss: 71256383.835\n",
      "Epoch: 1964, Loss: 64339584.427\n",
      "Epoch: 1965, Loss: 59667415.922\n",
      "Epoch: 1966, Loss: 55408558.017\n",
      "Epoch: 1967, Loss: 59369841.986\n",
      "Epoch: 1968, Loss: 53880994.216\n",
      "Epoch: 1969, Loss: 60191743.877\n",
      "Epoch: 1970, Loss: 65219106.657\n",
      "Epoch: 1971, Loss: 52525681.081\n",
      "Epoch: 1972, Loss: 65213078.152\n",
      "Epoch: 1973, Loss: 55065023.580\n",
      "Epoch: 1974, Loss: 68862634.611\n",
      "Epoch: 1975, Loss: 57600723.908\n",
      "Epoch: 1976, Loss: 66175113.536\n",
      "Epoch: 1977, Loss: 68997496.223\n",
      "Epoch: 1978, Loss: 55625191.328\n",
      "Epoch: 1979, Loss: 52113080.996\n",
      "Epoch: 1980, Loss: 57319138.795\n",
      "Epoch: 1981, Loss: 55880566.722\n",
      "Epoch: 1982, Loss: 67470559.105\n",
      "Epoch: 1983, Loss: 70476521.209\n",
      "Epoch: 1984, Loss: 60753987.347\n",
      "Epoch: 1985, Loss: 49997044.935\n",
      "Epoch: 1986, Loss: 59693508.664\n",
      "Epoch: 1987, Loss: 51442940.872\n",
      "Epoch: 1988, Loss: 64868597.380\n",
      "Epoch: 1989, Loss: 49087111.625\n",
      "Epoch: 1990, Loss: 63769170.202\n",
      "Epoch: 1991, Loss: 69343696.067\n",
      "Epoch: 1992, Loss: 67311543.801\n",
      "Epoch: 1993, Loss: 65836442.576\n",
      "Epoch: 1994, Loss: 56829933.545\n",
      "Epoch: 1995, Loss: 53823513.660\n",
      "Epoch: 1996, Loss: 59604364.392\n",
      "Epoch: 1997, Loss: 68525618.297\n",
      "Epoch: 1998, Loss: 59250775.335\n",
      "Epoch: 1999, Loss: 54047416.643\n",
      "Epoch: 2000, Loss: 75647229.639\n",
      "Epoch: 2001, Loss: 69008151.543\n",
      "Epoch: 2002, Loss: 67824496.683\n",
      "Epoch: 2003, Loss: 58110934.998\n",
      "Epoch: 2004, Loss: 53856569.395\n",
      "Epoch: 2005, Loss: 53381333.592\n",
      "Epoch: 2006, Loss: 48567386.114\n",
      "Epoch: 2007, Loss: 61686372.937\n",
      "Epoch: 2008, Loss: 51331420.913\n",
      "Epoch: 2009, Loss: 55209434.016\n",
      "Epoch: 2010, Loss: 71960173.935\n",
      "Epoch: 2011, Loss: 57238122.492\n",
      "Epoch: 2012, Loss: 64267527.158\n",
      "Epoch: 2013, Loss: 78625762.977\n",
      "Epoch: 2014, Loss: 61294113.382\n",
      "Epoch: 2015, Loss: 57358179.260\n",
      "Epoch: 2016, Loss: 54720410.811\n",
      "Epoch: 2017, Loss: 50300003.915\n",
      "Epoch: 2018, Loss: 56385064.382\n",
      "Epoch: 2019, Loss: 47196447.675\n",
      "Epoch: 2020, Loss: 66201620.828\n",
      "Epoch: 2021, Loss: 65129598.081\n",
      "Epoch: 2022, Loss: 64025885.581\n",
      "Epoch: 2023, Loss: 58914077.702\n",
      "Epoch: 2024, Loss: 50462477.635\n",
      "Epoch: 2025, Loss: 51205503.461\n",
      "Epoch: 2026, Loss: 53032412.785\n",
      "Epoch: 2027, Loss: 66451918.599\n",
      "Epoch: 2028, Loss: 57907376.663\n",
      "Epoch: 2029, Loss: 62709207.679\n",
      "Epoch: 2030, Loss: 49756708.805\n",
      "Epoch: 2031, Loss: 59537399.178\n",
      "Epoch: 2032, Loss: 55797988.380\n",
      "Epoch: 2033, Loss: 59595021.862\n",
      "Epoch: 2034, Loss: 52121288.269\n",
      "Epoch: 2035, Loss: 55783902.457\n",
      "Epoch: 2036, Loss: 61577551.294\n",
      "Epoch: 2037, Loss: 58437680.623\n",
      "Epoch: 2038, Loss: 63400001.422\n",
      "Epoch: 2039, Loss: 54692309.632\n",
      "Epoch: 2040, Loss: 67593463.537\n",
      "Epoch: 2041, Loss: 57745036.799\n",
      "Epoch: 2042, Loss: 59286010.736\n",
      "Epoch: 2043, Loss: 57846780.326\n",
      "Epoch: 2044, Loss: 61351961.151\n",
      "Epoch: 2045, Loss: 56216132.358\n",
      "Epoch: 2046, Loss: 58591782.370\n",
      "Epoch: 2047, Loss: 50797961.835\n",
      "Epoch: 2048, Loss: 72166220.471\n",
      "Epoch: 2049, Loss: 65147527.124\n",
      "Epoch: 2050, Loss: 65238451.919\n",
      "Epoch: 2051, Loss: 55104399.833\n",
      "Epoch: 2052, Loss: 77999337.997\n",
      "Epoch: 2053, Loss: 71231443.908\n",
      "Epoch: 2054, Loss: 53659018.006\n",
      "Epoch: 2055, Loss: 64098898.296\n",
      "Epoch: 2056, Loss: 51684305.199\n",
      "Epoch: 2057, Loss: 54965209.985\n",
      "Epoch: 2058, Loss: 65789288.356\n",
      "Epoch: 2059, Loss: 54451814.522\n",
      "Epoch: 2060, Loss: 50987937.602\n",
      "Epoch: 2061, Loss: 61904055.827\n",
      "Epoch: 2062, Loss: 59549268.859\n",
      "Epoch: 2063, Loss: 57969490.873\n",
      "Epoch: 2064, Loss: 59909684.743\n",
      "Epoch: 2065, Loss: 60934606.854\n",
      "Epoch: 2066, Loss: 51604075.608\n",
      "Epoch: 2067, Loss: 72847139.828\n",
      "Epoch: 2068, Loss: 51193980.383\n",
      "Epoch: 2069, Loss: 55038600.391\n",
      "Epoch: 2070, Loss: 53640460.901\n",
      "Epoch: 2071, Loss: 60044656.046\n",
      "Epoch: 2072, Loss: 51784931.389\n",
      "Epoch: 2073, Loss: 65550648.038\n",
      "Epoch: 2074, Loss: 74361409.759\n",
      "Epoch: 2075, Loss: 58499096.411\n",
      "Epoch: 2076, Loss: 59045600.688\n",
      "Epoch: 2077, Loss: 57154065.912\n",
      "Epoch: 2078, Loss: 64812247.995\n",
      "Epoch: 2079, Loss: 54001326.744\n",
      "Epoch: 2080, Loss: 49665936.484\n",
      "Epoch: 2081, Loss: 61662036.968\n",
      "Epoch: 2082, Loss: 53740838.974\n",
      "Epoch: 2083, Loss: 48778770.542\n",
      "Epoch: 2084, Loss: 58009590.074\n",
      "Epoch: 2085, Loss: 51222194.827\n",
      "Epoch: 2086, Loss: 52860975.130\n",
      "Epoch: 2087, Loss: 54567424.710\n",
      "Epoch: 2088, Loss: 61900302.169\n",
      "Epoch: 2089, Loss: 60937978.648\n",
      "Epoch: 2090, Loss: 64687067.483\n",
      "Epoch: 2091, Loss: 58870327.306\n",
      "Epoch: 2092, Loss: 69669857.178\n",
      "Epoch: 2093, Loss: 75237577.618\n",
      "Epoch: 2094, Loss: 56648985.257\n",
      "Epoch: 2095, Loss: 63700435.991\n",
      "Epoch: 2096, Loss: 60279186.826\n",
      "Epoch: 2097, Loss: 59284078.797\n",
      "Epoch: 2098, Loss: 59840983.064\n",
      "Epoch: 2099, Loss: 58026734.204\n",
      "Epoch: 2100, Loss: 55508936.190\n",
      "Epoch: 2101, Loss: 51338009.491\n",
      "Epoch: 2102, Loss: 53473723.845\n",
      "Epoch: 2103, Loss: 56940430.597\n",
      "Epoch: 2104, Loss: 51988925.296\n",
      "Epoch: 2105, Loss: 61163827.944\n",
      "Epoch: 2106, Loss: 56125771.234\n",
      "Epoch: 2107, Loss: 64677009.888\n",
      "Epoch: 2108, Loss: 53368093.735\n",
      "Epoch: 2109, Loss: 55435056.426\n",
      "Epoch: 2110, Loss: 60583753.239\n",
      "Epoch: 2111, Loss: 67558442.107\n",
      "Epoch: 2112, Loss: 60274063.173\n",
      "Epoch: 2113, Loss: 60486220.114\n",
      "Epoch: 2114, Loss: 62270838.688\n",
      "Epoch: 2115, Loss: 72619430.404\n",
      "Epoch: 2116, Loss: 66112024.733\n",
      "Epoch: 2117, Loss: 60294124.986\n",
      "Epoch: 2118, Loss: 71325531.264\n",
      "Epoch: 2119, Loss: 55369975.253\n",
      "Epoch: 2120, Loss: 56493094.630\n",
      "Epoch: 2121, Loss: 68726748.297\n",
      "Epoch: 2122, Loss: 52011033.008\n",
      "Epoch: 2123, Loss: 51368330.291\n",
      "Epoch: 2124, Loss: 67088187.833\n",
      "Epoch: 2125, Loss: 56009823.015\n",
      "Epoch: 2126, Loss: 64467751.405\n",
      "Epoch: 2127, Loss: 51192227.993\n",
      "Epoch: 2128, Loss: 61571576.689\n",
      "Epoch: 2129, Loss: 60522483.386\n",
      "Epoch: 2130, Loss: 48315544.260\n",
      "Epoch: 2131, Loss: 67044180.834\n",
      "Epoch: 2132, Loss: 66527575.978\n",
      "Epoch: 2133, Loss: 61954316.129\n",
      "Epoch: 2134, Loss: 59931341.174\n",
      "Epoch: 2135, Loss: 58346928.919\n",
      "Epoch: 2136, Loss: 67493707.789\n",
      "Epoch: 2137, Loss: 60838499.333\n",
      "Epoch: 2138, Loss: 69259030.989\n",
      "Epoch: 2139, Loss: 50264356.583\n",
      "Epoch: 2140, Loss: 55306187.461\n",
      "Epoch: 2141, Loss: 59210041.267\n",
      "Epoch: 2142, Loss: 57684466.670\n",
      "Epoch: 2143, Loss: 72896024.437\n",
      "Epoch: 2144, Loss: 70599259.386\n",
      "Epoch: 2145, Loss: 63496372.542\n",
      "Epoch: 2146, Loss: 73489613.938\n",
      "Epoch: 2147, Loss: 63252822.309\n",
      "Epoch: 2148, Loss: 69380397.044\n",
      "Epoch: 2149, Loss: 69193460.950\n",
      "Epoch: 2150, Loss: 67992184.760\n",
      "Epoch: 2151, Loss: 63162281.526\n",
      "Epoch: 2152, Loss: 55834677.132\n",
      "Epoch: 2153, Loss: 57223805.824\n",
      "Epoch: 2154, Loss: 59866452.727\n",
      "Epoch: 2155, Loss: 69795547.703\n",
      "Epoch: 2156, Loss: 69491988.936\n",
      "Epoch: 2157, Loss: 55065577.179\n",
      "Epoch: 2158, Loss: 61865197.044\n",
      "Epoch: 2159, Loss: 57597439.595\n",
      "Epoch: 2160, Loss: 62782346.465\n",
      "Epoch: 2161, Loss: 63147831.549\n",
      "Epoch: 2162, Loss: 54820467.661\n",
      "Epoch: 2163, Loss: 65728011.785\n",
      "Epoch: 2164, Loss: 53148161.792\n",
      "Epoch: 2165, Loss: 77805626.859\n",
      "Epoch: 2166, Loss: 59865374.810\n",
      "Epoch: 2167, Loss: 56206906.630\n",
      "Epoch: 2168, Loss: 65125449.839\n",
      "Epoch: 2169, Loss: 58329265.417\n",
      "Epoch: 2170, Loss: 47880355.715\n",
      "Epoch: 2171, Loss: 58397302.943\n",
      "Epoch: 2172, Loss: 51321969.198\n",
      "Epoch: 2173, Loss: 52602157.509\n",
      "Epoch: 2174, Loss: 58605328.894\n",
      "Epoch: 2175, Loss: 61472989.388\n",
      "Epoch: 2176, Loss: 57683296.926\n",
      "Epoch: 2177, Loss: 61159047.891\n",
      "Epoch: 2178, Loss: 43489932.676\n",
      "Epoch: 2179, Loss: 50631031.317\n",
      "Epoch: 2180, Loss: 45404086.657\n",
      "Epoch: 2181, Loss: 65626585.907\n",
      "Epoch: 2182, Loss: 50833039.803\n",
      "Epoch: 2183, Loss: 53109626.776\n",
      "Epoch: 2184, Loss: 71402211.148\n",
      "Epoch: 2185, Loss: 63016116.294\n",
      "Epoch: 2186, Loss: 53402947.650\n",
      "Epoch: 2187, Loss: 60426978.828\n",
      "Epoch: 2188, Loss: 66823450.446\n",
      "Epoch: 2189, Loss: 61842381.260\n",
      "Epoch: 2190, Loss: 70469298.392\n",
      "Epoch: 2191, Loss: 60922433.563\n",
      "Epoch: 2192, Loss: 62073433.096\n",
      "Epoch: 2193, Loss: 48111567.180\n",
      "Epoch: 2194, Loss: 54808270.065\n",
      "Epoch: 2195, Loss: 60947864.248\n",
      "Epoch: 2196, Loss: 70989066.590\n",
      "Epoch: 2197, Loss: 60381713.852\n",
      "Epoch: 2198, Loss: 64981499.416\n",
      "Epoch: 2199, Loss: 62362899.349\n",
      "Epoch: 2200, Loss: 54028592.614\n",
      "Epoch: 2201, Loss: 70249733.874\n",
      "Epoch: 2202, Loss: 54790709.362\n",
      "Epoch: 2203, Loss: 64071960.105\n",
      "Epoch: 2204, Loss: 54697274.094\n",
      "Epoch: 2205, Loss: 67424237.675\n",
      "Epoch: 2206, Loss: 67790908.036\n",
      "Epoch: 2207, Loss: 64583023.304\n",
      "Epoch: 2208, Loss: 59306868.628\n",
      "Epoch: 2209, Loss: 64967505.329\n",
      "Epoch: 2210, Loss: 66130751.870\n",
      "Epoch: 2211, Loss: 46498126.153\n",
      "Epoch: 2212, Loss: 62494412.317\n",
      "Epoch: 2213, Loss: 72049055.676\n",
      "Epoch: 2214, Loss: 53144978.012\n",
      "Epoch: 2215, Loss: 58037614.952\n",
      "Epoch: 2216, Loss: 63303550.462\n",
      "Epoch: 2217, Loss: 60457606.059\n",
      "Epoch: 2218, Loss: 60650406.049\n",
      "Epoch: 2219, Loss: 60168405.254\n",
      "Epoch: 2220, Loss: 62600343.972\n",
      "Epoch: 2221, Loss: 70067898.632\n",
      "Epoch: 2222, Loss: 50465022.415\n",
      "Epoch: 2223, Loss: 60554489.866\n",
      "Epoch: 2224, Loss: 45168106.642\n",
      "Epoch: 2225, Loss: 60053665.741\n",
      "Epoch: 2226, Loss: 63788601.052\n",
      "Epoch: 2227, Loss: 71639459.341\n",
      "Epoch: 2228, Loss: 62233349.272\n",
      "Epoch: 2229, Loss: 63883774.460\n",
      "Epoch: 2230, Loss: 57894816.569\n",
      "Epoch: 2231, Loss: 61648213.611\n",
      "Epoch: 2232, Loss: 71847672.770\n",
      "Epoch: 2233, Loss: 64770464.074\n",
      "Epoch: 2234, Loss: 58780874.165\n",
      "Epoch: 2235, Loss: 56264429.403\n",
      "Epoch: 2236, Loss: 57589527.784\n",
      "Epoch: 2237, Loss: 61111830.282\n",
      "Epoch: 2238, Loss: 60024036.148\n",
      "Epoch: 2239, Loss: 66012229.096\n",
      "Epoch: 2240, Loss: 64181861.394\n",
      "Epoch: 2241, Loss: 70085374.443\n",
      "Epoch: 2242, Loss: 56785161.965\n",
      "Epoch: 2243, Loss: 59386366.034\n",
      "Epoch: 2244, Loss: 54015206.539\n",
      "Epoch: 2245, Loss: 59392851.354\n",
      "Epoch: 2246, Loss: 63250258.555\n",
      "Epoch: 2247, Loss: 52964218.279\n",
      "Epoch: 2248, Loss: 71326437.120\n",
      "Epoch: 2249, Loss: 51190573.153\n",
      "Epoch: 2250, Loss: 46581698.834\n",
      "Epoch: 2251, Loss: 61536955.469\n",
      "Epoch: 2252, Loss: 58089352.706\n",
      "Epoch: 2253, Loss: 56862344.987\n",
      "Epoch: 2254, Loss: 61883251.497\n",
      "Epoch: 2255, Loss: 57723306.050\n",
      "Epoch: 2256, Loss: 63029351.280\n",
      "Epoch: 2257, Loss: 65317357.264\n",
      "Epoch: 2258, Loss: 55697493.383\n",
      "Epoch: 2259, Loss: 51506065.400\n",
      "Epoch: 2260, Loss: 63106922.510\n",
      "Epoch: 2261, Loss: 63824581.722\n",
      "Epoch: 2262, Loss: 53171236.019\n",
      "Epoch: 2263, Loss: 59372238.244\n",
      "Epoch: 2264, Loss: 74341352.282\n",
      "Epoch: 2265, Loss: 65885210.102\n",
      "Epoch: 2266, Loss: 49494062.072\n",
      "Epoch: 2267, Loss: 54688251.840\n",
      "Epoch: 2268, Loss: 60387139.752\n",
      "Epoch: 2269, Loss: 61641574.680\n",
      "Epoch: 2270, Loss: 65329572.695\n",
      "Epoch: 2271, Loss: 70467556.036\n",
      "Epoch: 2272, Loss: 84027316.175\n",
      "Epoch: 2273, Loss: 64272424.216\n",
      "Epoch: 2274, Loss: 68155367.702\n",
      "Epoch: 2275, Loss: 55166301.158\n",
      "Epoch: 2276, Loss: 52955133.794\n",
      "Epoch: 2277, Loss: 68910983.098\n",
      "Epoch: 2278, Loss: 65624879.196\n",
      "Epoch: 2279, Loss: 49801802.203\n",
      "Epoch: 2280, Loss: 59761256.533\n",
      "Epoch: 2281, Loss: 61088500.181\n",
      "Epoch: 2282, Loss: 66473642.541\n",
      "Epoch: 2283, Loss: 70165541.479\n",
      "Epoch: 2284, Loss: 63174977.375\n",
      "Epoch: 2285, Loss: 65618369.875\n",
      "Epoch: 2286, Loss: 62486179.278\n",
      "Epoch: 2287, Loss: 54786776.602\n",
      "Epoch: 2288, Loss: 59937043.355\n",
      "Epoch: 2289, Loss: 63642880.053\n",
      "Epoch: 2290, Loss: 50913461.117\n",
      "Epoch: 2291, Loss: 61187904.812\n",
      "Epoch: 2292, Loss: 57644208.396\n",
      "Epoch: 2293, Loss: 71624600.018\n",
      "Epoch: 2294, Loss: 61196946.238\n",
      "Epoch: 2295, Loss: 52980367.694\n",
      "Epoch: 2296, Loss: 68762945.279\n",
      "Epoch: 2297, Loss: 65849514.936\n",
      "Epoch: 2298, Loss: 61700700.617\n",
      "Epoch: 2299, Loss: 56156954.499\n",
      "Epoch: 2300, Loss: 61560557.632\n",
      "Epoch: 2301, Loss: 64951287.650\n",
      "Epoch: 2302, Loss: 68648707.927\n",
      "Epoch: 2303, Loss: 48293935.135\n",
      "Epoch: 2304, Loss: 68175158.635\n",
      "Epoch: 2305, Loss: 62186018.468\n",
      "Epoch: 2306, Loss: 57468465.676\n",
      "Epoch: 2307, Loss: 59685735.988\n",
      "Epoch: 2308, Loss: 61011994.379\n",
      "Epoch: 2309, Loss: 63053203.568\n",
      "Epoch: 2310, Loss: 53426316.870\n",
      "Epoch: 2311, Loss: 54692156.633\n",
      "Epoch: 2312, Loss: 62308635.452\n",
      "Epoch: 2313, Loss: 50744403.000\n",
      "Epoch: 2314, Loss: 60495791.636\n",
      "Epoch: 2315, Loss: 57888371.364\n",
      "Epoch: 2316, Loss: 64482712.074\n",
      "Epoch: 2317, Loss: 50400593.611\n",
      "Epoch: 2318, Loss: 69366065.976\n",
      "Epoch: 2319, Loss: 53278867.511\n",
      "Epoch: 2320, Loss: 57885392.771\n",
      "Epoch: 2321, Loss: 57587077.766\n",
      "Epoch: 2322, Loss: 66532126.249\n",
      "Epoch: 2323, Loss: 61755017.919\n",
      "Epoch: 2324, Loss: 63429767.753\n",
      "Epoch: 2325, Loss: 62698309.719\n",
      "Epoch: 2326, Loss: 49199933.299\n",
      "Epoch: 2327, Loss: 62834729.990\n",
      "Epoch: 2328, Loss: 39414155.009\n",
      "Epoch: 2329, Loss: 56192714.269\n",
      "Epoch: 2330, Loss: 55274130.563\n",
      "Epoch: 2331, Loss: 52151739.936\n",
      "Epoch: 2332, Loss: 63889500.007\n",
      "Epoch: 2333, Loss: 58950977.626\n",
      "Epoch: 2334, Loss: 72985668.062\n",
      "Epoch: 2335, Loss: 58722041.557\n",
      "Epoch: 2336, Loss: 54691976.468\n",
      "Epoch: 2337, Loss: 61209100.177\n",
      "Epoch: 2338, Loss: 61539830.838\n",
      "Epoch: 2339, Loss: 57524770.403\n",
      "Epoch: 2340, Loss: 59469829.393\n",
      "Epoch: 2341, Loss: 58537008.935\n",
      "Epoch: 2342, Loss: 49080652.534\n",
      "Epoch: 2343, Loss: 46177657.830\n",
      "Epoch: 2344, Loss: 64152751.839\n",
      "Epoch: 2345, Loss: 68505997.616\n",
      "Epoch: 2346, Loss: 61765123.864\n",
      "Epoch: 2347, Loss: 57690554.020\n",
      "Epoch: 2348, Loss: 48022973.043\n",
      "Epoch: 2349, Loss: 62633964.769\n",
      "Epoch: 2350, Loss: 53951041.131\n",
      "Epoch: 2351, Loss: 50337227.977\n",
      "Epoch: 2352, Loss: 50629196.320\n",
      "Epoch: 2353, Loss: 57202834.996\n",
      "Epoch: 2354, Loss: 65152228.335\n",
      "Epoch: 2355, Loss: 60608167.986\n",
      "Epoch: 2356, Loss: 59562324.725\n",
      "Epoch: 2357, Loss: 64638609.800\n",
      "Epoch: 2358, Loss: 58273443.484\n",
      "Epoch: 2359, Loss: 48780001.145\n",
      "Epoch: 2360, Loss: 65564626.948\n",
      "Epoch: 2361, Loss: 56622417.028\n",
      "Epoch: 2362, Loss: 54976535.596\n",
      "Epoch: 2363, Loss: 56713699.975\n",
      "Epoch: 2364, Loss: 58084445.099\n",
      "Epoch: 2365, Loss: 63891051.495\n",
      "Epoch: 2366, Loss: 60658979.521\n",
      "Epoch: 2367, Loss: 58247896.331\n",
      "Epoch: 2368, Loss: 59935287.148\n",
      "Epoch: 2369, Loss: 75756100.610\n",
      "Epoch: 2370, Loss: 65998384.619\n",
      "Epoch: 2371, Loss: 55311875.258\n",
      "Epoch: 2372, Loss: 52892730.613\n",
      "Epoch: 2373, Loss: 58977892.137\n",
      "Epoch: 2374, Loss: 62990735.927\n",
      "Epoch: 2375, Loss: 61882139.172\n",
      "Epoch: 2376, Loss: 70764662.045\n",
      "Epoch: 2377, Loss: 63031123.134\n",
      "Epoch: 2378, Loss: 60942236.740\n",
      "Epoch: 2379, Loss: 63547216.572\n",
      "Epoch: 2380, Loss: 73828634.034\n",
      "Epoch: 2381, Loss: 65554300.170\n",
      "Epoch: 2382, Loss: 67014491.979\n",
      "Epoch: 2383, Loss: 52697425.668\n",
      "Epoch: 2384, Loss: 57257019.615\n",
      "Epoch: 2385, Loss: 37580840.946\n",
      "Epoch: 2386, Loss: 63047025.149\n",
      "Epoch: 2387, Loss: 71312747.835\n",
      "Epoch: 2388, Loss: 53221085.924\n",
      "Epoch: 2389, Loss: 53607835.274\n",
      "Epoch: 2390, Loss: 68367225.990\n",
      "Epoch: 2391, Loss: 56844068.751\n",
      "Epoch: 2392, Loss: 52469081.042\n",
      "Epoch: 2393, Loss: 60485041.491\n",
      "Epoch: 2394, Loss: 60273296.743\n",
      "Epoch: 2395, Loss: 75412093.459\n",
      "Epoch: 2396, Loss: 67903321.551\n",
      "Epoch: 2397, Loss: 51000867.604\n",
      "Epoch: 2398, Loss: 50207534.253\n",
      "Epoch: 2399, Loss: 53865497.302\n",
      "Epoch: 2400, Loss: 61912511.162\n",
      "Epoch: 2401, Loss: 54805533.478\n",
      "Epoch: 2402, Loss: 65862610.242\n",
      "Epoch: 2403, Loss: 54104015.938\n",
      "Epoch: 2404, Loss: 62495231.034\n",
      "Epoch: 2405, Loss: 71504939.324\n",
      "Epoch: 2406, Loss: 67586049.818\n",
      "Epoch: 2407, Loss: 68469227.113\n",
      "Epoch: 2408, Loss: 46638808.561\n",
      "Epoch: 2409, Loss: 55728508.211\n",
      "Epoch: 2410, Loss: 66069934.353\n",
      "Epoch: 2411, Loss: 63879815.432\n",
      "Epoch: 2412, Loss: 57365167.527\n",
      "Epoch: 2413, Loss: 64982770.956\n",
      "Epoch: 2414, Loss: 75624346.566\n",
      "Epoch: 2415, Loss: 52141102.454\n",
      "Epoch: 2416, Loss: 55713970.053\n",
      "Epoch: 2417, Loss: 52923376.390\n",
      "Epoch: 2418, Loss: 61279707.600\n",
      "Epoch: 2419, Loss: 65413814.999\n",
      "Epoch: 2420, Loss: 53500845.958\n",
      "Epoch: 2421, Loss: 68728518.467\n",
      "Epoch: 2422, Loss: 62338261.964\n",
      "Epoch: 2423, Loss: 56303143.395\n",
      "Epoch: 2424, Loss: 61178687.563\n",
      "Epoch: 2425, Loss: 64642655.156\n",
      "Epoch: 2426, Loss: 56740507.962\n",
      "Epoch: 2427, Loss: 48927044.271\n",
      "Epoch: 2428, Loss: 60074267.598\n",
      "Epoch: 2429, Loss: 58516607.198\n",
      "Epoch: 2430, Loss: 73502674.023\n",
      "Epoch: 2431, Loss: 54318357.184\n",
      "Epoch: 2432, Loss: 51667566.531\n",
      "Epoch: 2433, Loss: 43393202.044\n",
      "Epoch: 2434, Loss: 44951641.879\n",
      "Epoch: 2435, Loss: 66943672.366\n",
      "Epoch: 2436, Loss: 61634086.677\n",
      "Epoch: 2437, Loss: 55805361.696\n",
      "Epoch: 2438, Loss: 69932986.223\n",
      "Epoch: 2439, Loss: 59763891.567\n",
      "Epoch: 2440, Loss: 49220239.762\n",
      "Epoch: 2441, Loss: 58136835.383\n",
      "Epoch: 2442, Loss: 65548463.726\n",
      "Epoch: 2443, Loss: 72385644.679\n",
      "Epoch: 2444, Loss: 59102103.977\n",
      "Epoch: 2445, Loss: 68574227.738\n",
      "Epoch: 2446, Loss: 54477561.474\n",
      "Epoch: 2447, Loss: 60627779.561\n",
      "Epoch: 2448, Loss: 61080166.907\n",
      "Epoch: 2449, Loss: 57032287.797\n",
      "Epoch: 2450, Loss: 53975701.242\n",
      "Epoch: 2451, Loss: 61890233.986\n",
      "Epoch: 2452, Loss: 47797124.334\n",
      "Epoch: 2453, Loss: 67334833.219\n",
      "Epoch: 2454, Loss: 56851062.710\n",
      "Epoch: 2455, Loss: 59332637.697\n",
      "Epoch: 2456, Loss: 64740809.512\n",
      "Epoch: 2457, Loss: 59740942.214\n",
      "Epoch: 2458, Loss: 61123981.171\n",
      "Epoch: 2459, Loss: 54153940.800\n",
      "Epoch: 2460, Loss: 41087979.953\n",
      "Epoch: 2461, Loss: 67228173.792\n",
      "Epoch: 2462, Loss: 55734762.306\n",
      "Epoch: 2463, Loss: 59739635.572\n",
      "Epoch: 2464, Loss: 55940249.630\n",
      "Epoch: 2465, Loss: 69837452.435\n",
      "Epoch: 2466, Loss: 64497039.353\n",
      "Epoch: 2467, Loss: 58499371.510\n",
      "Epoch: 2468, Loss: 57509016.200\n",
      "Epoch: 2469, Loss: 66618131.989\n",
      "Epoch: 2470, Loss: 64494585.713\n",
      "Epoch: 2471, Loss: 65619554.058\n",
      "Epoch: 2472, Loss: 57046616.905\n",
      "Epoch: 2473, Loss: 59941710.729\n",
      "Epoch: 2474, Loss: 49680580.439\n",
      "Epoch: 2475, Loss: 58496267.695\n",
      "Epoch: 2476, Loss: 53891668.842\n",
      "Epoch: 2477, Loss: 54899470.222\n",
      "Epoch: 2478, Loss: 72474256.521\n",
      "Epoch: 2479, Loss: 69035246.889\n",
      "Epoch: 2480, Loss: 63976006.636\n",
      "Epoch: 2481, Loss: 53783422.666\n",
      "Epoch: 2482, Loss: 66897365.263\n",
      "Epoch: 2483, Loss: 55775526.253\n",
      "Epoch: 2484, Loss: 73076880.742\n",
      "Epoch: 2485, Loss: 53868901.110\n",
      "Epoch: 2486, Loss: 50196331.185\n",
      "Epoch: 2487, Loss: 72316665.522\n",
      "Epoch: 2488, Loss: 67343888.318\n",
      "Epoch: 2489, Loss: 55791701.967\n",
      "Epoch: 2490, Loss: 71571689.008\n",
      "Epoch: 2491, Loss: 54515840.749\n",
      "Epoch: 2492, Loss: 64087086.925\n",
      "Epoch: 2493, Loss: 67257796.322\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Have fun with the number of epochs!\n",
    "\n",
    "Be warned that if you increase them too much,\n",
    "the VM will time out :)\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle, resample\n",
    "\n",
    "# Load data\n",
    "X_ = X\n",
    "y_ = y\n",
    "\n",
    "\n",
    "n_features = X_.shape[1]\n",
    "n_hidden = 15\n",
    "W1_ = np.random.randn(n_features, n_hidden)\n",
    "b1_ = np.zeros(n_hidden)\n",
    "W2_ = np.random.randn(n_hidden, 1)\n",
    "b2_ = np.zeros(1)\n",
    "\n",
    "# Neural network\n",
    "X, y = Input(), Input()\n",
    "W1, b1 = Input(), Input()\n",
    "W2, b2 = Input(), Input()\n",
    "\n",
    "l1 = Linear(X, W1, b1)\n",
    "s1 = Sigmoid(l1)\n",
    "l2 = Linear(s1, W2, b2)\n",
    "cost = MSE(y, l2)\n",
    "\n",
    "feed_dict = {\n",
    "    X: X_,\n",
    "    y: y_,\n",
    "    W1: W1_,\n",
    "    b1: b1_,\n",
    "    W2: W2_,\n",
    "    b2: b2_\n",
    "}\n",
    "\n",
    "epochs = 10000\n",
    "# Total number of examples\n",
    "m = X_.shape[0]\n",
    "batch_size = 11\n",
    "steps_per_epoch = m // batch_size\n",
    "\n",
    "graph = topological_sort(feed_dict)\n",
    "trainables = [W1, b1, W2, b2]\n",
    "\n",
    "print(\"Total number of examples = {}\".format(m))\n",
    "\n",
    "# Step 4\n",
    "for i in range(epochs):\n",
    "    loss = 0\n",
    "    for j in range(steps_per_epoch):\n",
    "        # Step 1\n",
    "        # Randomly sample a batch of examples\n",
    "        X_batch, y_batch = resample(X_, y_, n_samples=batch_size)\n",
    "\n",
    "        # Reset value of X and y Inputs\n",
    "        X.value = X_batch\n",
    "        y.value = y_batch\n",
    "\n",
    "        # Step 2\n",
    "        forward_and_backward(graph)\n",
    "\n",
    "        # Step 3\n",
    "        sgd_update(trainables)\n",
    "\n",
    "        loss += graph[-1].value\n",
    "\n",
    "    print(\"Epoch: {}, Loss: {:.3f}\".format(i+1, loss/steps_per_epoch))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
